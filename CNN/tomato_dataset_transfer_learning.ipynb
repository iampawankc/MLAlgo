{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras import layers as L\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.applications import vgg16\n",
    "from keras.layers import Flatten, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = '/Users/pawankumarkc/Downloads/Datasets_to_delete/tomato_leaf_images/train'\n",
    "validation_data = '/Users/pawankumarkc/Downloads/Datasets_to_delete/tomato_leaf_images/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lebel the files name by using integer\n",
    "\n",
    "labels_dict = {'AmericanLeafMiner':0, \n",
    "               'Healthy':1, \n",
    "               'MagnesiumDeficiency':2, \n",
    "               'SerpentineLeafMiner':3 }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type([f for f in os.listdir(training_data) if f!='.DS_Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(os.listdir(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_df \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(training_data):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     imgs_path \u001b[39m=\u001b[39m training_data \u001b[39m/\u001b[39m folder\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m#Get the list of all images stored in that directory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     imgs \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(imgs_path\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*.jpg\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_df \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(training_data):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     imgs_path \u001b[39m=\u001b[39m training_data \u001b[39m/\u001b[39m folder\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m#Get the list of all images stored in that directory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/CNN/tomato_dataset_transfer_learning.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     imgs \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(imgs_path\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*.jpg\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mpydev_state \u001b[39m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_wait_suspend(thread, frame, event, arg)\n\u001b[1;32m    989\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_wait_suspend\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdo_wait_suspend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Creating dataframe for training dataset\n",
    "\n",
    "train_df = []\n",
    "\n",
    "for folder in os.listdir(training_data):\n",
    "    imgs_path = training_data / folder\n",
    "    #Get the list of all images stored in that directory\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "\n",
    "    #Store each image path and corresponding label\n",
    "    for img_name in imgs:\n",
    "        train_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
    "\n",
    "#Shuffel the dataset\n",
    "train_df = train_df.sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe for test dataset\n",
    "\n",
    "valid_df = []\n",
    "\n",
    "for folder in os.listdir(validation_data):\n",
    "    imgs_path = validation_data / folder\n",
    "    #Get the list of all images stored in that directory\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "\n",
    "    #Store each image path and corresponding label\n",
    "    for img_name in imgs:\n",
    "        valid_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
    "\n",
    "#Shuffel the dataset\n",
    "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration\n",
    "\n",
    "#dimentions to consider for the image\n",
    "img_rows, img_cols, img_channels = 224, 244, 3\n",
    "\n",
    "#Batch size\n",
    "batch_size = 8\n",
    "\n",
    "#Total no. of classes\n",
    "nb_classes = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data augumentation (Alternative for DataImageGenerator)\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seed = 1234\n",
    "ia.seed(seed)\n",
    "\n",
    "#Augumentation sqeuence \n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), #Horizontal flip\n",
    "    iaa.Affine(rotate=20), #Affine algo for rotation\n",
    "    iaa.Multiply((1.2, 1.5)), #Zooming\n",
    "\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data generator\n",
    "\n",
    "def data_generator(data, batch_size, is_validation_data = False, preprocessing_function = None):\n",
    "    n = len(data)\n",
    "    nb_batches = int(np.ceil(n/batch_size)) #ceil value gives above value(rounded of) of a given number\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    while True:\n",
    "        if not is_validation_data:\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        for i in range(nb_batches):\n",
    "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
    "            nb_examples = len(next_batch_indices)\n",
    "\n",
    "            #Define 2 numpy array for containing batch data and labels\n",
    "            batch_data = np.zeros((nb_examples, img_rows, img_cols, img_channels), dtype=np.float32) \n",
    "            batch_labels = np.zeros((nb_examples, nb_classes), dtype=np.float32)\n",
    "\n",
    "            #Process the next batch \n",
    "            for j, idx in enumerate(next_batch_indices):\n",
    "                img = cv2.imread(data.iloc[idx]['image'])\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                label = data.iloc[idx]['label']\n",
    "\n",
    "                if not is_validation_data:\n",
    "                    img = seq.augment_image(img)\n",
    "                \n",
    "                img = cv2.resize(img, (img_rows, img_cols))\n",
    "                batch_data[j] = img\n",
    "                batch_labels[j] = to_categorical(label, num_classes=nb_classes)\n",
    "\n",
    "                if preprocessing_function is not None:\n",
    "                    batch_data = preprocessing_function(batch_data)\n",
    "\n",
    "                yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 model\n",
    "\n",
    "preprocessing_function = vgg16.preprocess_input\n",
    "\n",
    "train_data_gen = data_generator(train_df, batch_size, preprocessing_function)\n",
    "valid_data_gen = data_generator(valid_df, batch_size, preprocessing_function, is_validation_data=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    base_model = vgg16.VGG16(\n",
    "        input_shape=(img_rows, img_cols, img_channels), \n",
    "        weights='imagenet', \n",
    "        include_top=True #True means change the CNN, Flase means we will not change anything\n",
    "        #Transfer learning with fine tuning\n",
    "    )\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the base model\n",
    "base_model = get_base_model()\n",
    "\n",
    "#Get output of second last dense layer\n",
    "base_model_output = base_model.layers[-2].output\n",
    "\n",
    "#Add new layers\n",
    "x = L.Dropout(0.5, name='drop2')(base_model_output)\n",
    "output = L.Dense(nb_classes, activation='softmax', name='fc3')(x)\n",
    "\n",
    "#define a new model\n",
    "model = Model(inputs = base_model.input, outputs = output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze all the base model layers\n",
    "\n",
    "for layer in base_model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "\n",
    "optimizer = RMSprop(0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training\n",
    "\n",
    "#Apply early stopping\n",
    "es = EarlyStopping(patience=100, restore_best_weights=True)\n",
    "\n",
    "#Checkpoint to save the model\n",
    "chkpt = ModelCheckpoint(filepath='model_checkpoint.h5', save_best_only=True)\n",
    "\n",
    "#No. of training and validation step for training and validation\n",
    "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
    "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
    "\n",
    "# Nuber of epochs\n",
    "nb_epochs = 50\n",
    "\n",
    "#train model\n",
    "hist = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps, \n",
    "                           validation_data=valid_data_gen, validation_steps=nb_valid_steps, \n",
    "                           callbacks=[es, chkpt])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EfficientNetB0 - To try\n",
    "\n",
    "base_model = keras.applications.EfficientNetB0(include_top=True)\n",
    "\n",
    "#Try - Xception model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

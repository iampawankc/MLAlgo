{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_paragraph = \"\"\"About the Program\n",
    "What is the total duration of the course?\n",
    "The total duration of the course is 16 months.\n",
    "What is the syllabus of the mentorship program?\n",
    "We will be covering the following modules:\n",
    "Python Fundamentals\n",
    "Python libraries for Data Science\n",
    "Data Analysis\n",
    "SQL for Data Science\n",
    "Maths for Machine Learning\n",
    "ML Algorithms\n",
    "Deep Learning with NLP\n",
    "Advance Deep Learning with Generative AI\n",
    "Practical ML\n",
    "MLOPs\n",
    "Case studies\n",
    "Will Deep Learning and NLP be a part of this program?\n",
    "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
    "What if I miss a live session? Will I get a recording of the session?\n",
    "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
    "Where can I find the class schedule?\n",
    "Checkout this google sheet to see month by month time table of the course\n",
    "What is the time duration of all the live sessions?\n",
    "Roughly, all the sessions last 3.5 hours.\n",
    "What is the language spoken by the instructor during the sessions?\n",
    "English\n",
    "How will I be informed about the upcoming class?\n",
    "You will get a mail from our side before every weekend session.\n",
    "Can I do this course if I am from a non-tech background?\n",
    "Yes, absolutely.\n",
    "I am late, can I join the program in the middle?\n",
    "Absolutely, you can join the program anytime.\n",
    "If I join/pay in the middle, will I be able to see all the past lectures?\n",
    "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
    "Where do I have to submit the task?\n",
    "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
    "Will we do case studies in the program?\n",
    "Yes.\n",
    "Where can we contact you?\n",
    "You can mail us at abc@learnbay.com\n",
    "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.Learnbay.in/\n",
    "Where can I reach out in case of a doubt after the session?\n",
    "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
    "If I join the program late, can I still ask past week doubts?\n",
    "Yes, just select past week doubt in the doubt clearance google form.\n",
    "Certificate and Placement Assistance related queries\n",
    "What is the criteria to get the certificate?\n",
    "There are 2 criterias:\n",
    "You have to pay the entire fee\n",
    "You have to attempt all the course assessments.\n",
    "Portfolio Building sessions\n",
    "Soft skill sessions\n",
    "Sessions with industry mentors\n",
    "Discussion on Job hunting strategies\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About the Program\\nWhat is the total duration of the course?\\nThe total duration of the course is 16 months.\\nWhat is the syllabus of the mentorship program?\\nWe will be covering the following modules:\\nPython Fundamentals\\nPython libraries for Data Science\\nData Analysis\\nSQL for Data Science\\nMaths for Machine Learning\\nML Algorithms\\nDeep Learning with NLP\\nAdvance Deep Learning with Generative AI\\nPractical ML\\nMLOPs\\nCase studies\\nWill Deep Learning and NLP be a part of this program?\\nNo, NLP and Deep Learning both are not a part of this program’s curriculum.\\nWhat if I miss a live session? Will I get a recording of the session?\\nYes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\\nWhere can I find the class schedule?\\nCheckout this google sheet to see month by month time table of the course\\nWhat is the time duration of all the live sessions?\\nRoughly, all the sessions last 3.5 hours.\\nWhat is the language spoken by the instructor during the sessions?\\nEnglish\\nHow will I be informed about the upcoming class?\\nYou will get a mail from our side before every weekend session.\\nCan I do this course if I am from a non-tech background?\\nYes, absolutely.\\nI am late, can I join the program in the middle?\\nAbsolutely, you can join the program anytime.\\nIf I join/pay in the middle, will I be able to see all the past lectures?\\nYes, once you make the payment you will be able to see all the past content in your dashboard.\\nWhere do I have to submit the task?\\nYou don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\\nWill we do case studies in the program?\\nYes.\\nWhere can we contact you?\\nYou can mail us at abc@learnbay.com\\nYou have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.Learnbay.in/\\nWhere can I reach out in case of a doubt after the session?\\nYou will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\\nIf I join the program late, can I still ask past week doubts?\\nYes, just select past week doubt in the doubt clearance google form.\\nCertificate and Placement Assistance related queries\\nWhat is the criteria to get the certificate?\\nThere are 2 criterias:\\nYou have to pay the entire fee\\nYou have to attempt all the course assessments.\\nPortfolio Building sessions\\nSoft skill sessions\\nSessions with industry mentors\\nDiscussion on Job hunting strategies'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([my_paragraph])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = []\n",
    "\n",
    "for sentence in my_paragraph.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequence.append(tokenized_sentence[: i+1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[45, 1],\n",
       " [45, 1, 10],\n",
       " [15, 11],\n",
       " [15, 11, 1],\n",
       " [15, 11, 1, 46],\n",
       " [15, 11, 1, 46, 33],\n",
       " [15, 11, 1, 46, 33, 7],\n",
       " [15, 11, 1, 46, 33, 7, 1],\n",
       " [15, 11, 1, 46, 33, 7, 1, 17],\n",
       " [1, 46],\n",
       " [1, 46, 33],\n",
       " [1, 46, 33, 7],\n",
       " [1, 46, 33, 7, 1],\n",
       " [1, 46, 33, 7, 1, 17],\n",
       " [1, 46, 33, 7, 1, 17, 11],\n",
       " [1, 46, 33, 7, 1, 17, 11, 78],\n",
       " [1, 46, 33, 7, 1, 17, 11, 78, 79],\n",
       " [15, 11],\n",
       " [15, 11, 1],\n",
       " [15, 11, 1, 80],\n",
       " [15, 11, 1, 80, 7],\n",
       " [15, 11, 1, 80, 7, 1],\n",
       " [15, 11, 1, 80, 7, 1, 81],\n",
       " [15, 11, 1, 80, 7, 1, 81, 10],\n",
       " [25, 4],\n",
       " [25, 4, 18],\n",
       " [25, 4, 18, 82],\n",
       " [25, 4, 18, 82, 1],\n",
       " [25, 4, 18, 82, 1, 83],\n",
       " [25, 4, 18, 82, 1, 83, 84],\n",
       " [47, 85],\n",
       " [47, 86],\n",
       " [47, 86, 19],\n",
       " [47, 86, 19, 34],\n",
       " [47, 86, 19, 34, 48],\n",
       " [34, 87],\n",
       " [88, 19],\n",
       " [88, 19, 34],\n",
       " [88, 19, 34, 48],\n",
       " [89, 19],\n",
       " [89, 19, 90],\n",
       " [89, 19, 90, 20],\n",
       " [49, 91],\n",
       " [26, 20],\n",
       " [26, 20, 27],\n",
       " [26, 20, 27, 35],\n",
       " [92, 26],\n",
       " [92, 26, 20],\n",
       " [92, 26, 20, 27],\n",
       " [92, 26, 20, 27, 93],\n",
       " [92, 26, 20, 27, 93, 94],\n",
       " [95, 49],\n",
       " [36, 50],\n",
       " [4, 26],\n",
       " [4, 26, 20],\n",
       " [4, 26, 20, 21],\n",
       " [4, 26, 20, 21, 35],\n",
       " [4, 26, 20, 21, 35, 18],\n",
       " [4, 26, 20, 21, 35, 18, 6],\n",
       " [4, 26, 20, 21, 35, 18, 6, 51],\n",
       " [4, 26, 20, 21, 35, 18, 6, 51, 7],\n",
       " [4, 26, 20, 21, 35, 18, 6, 51, 7, 28],\n",
       " [4, 26, 20, 21, 35, 18, 6, 51, 7, 28, 10],\n",
       " [97, 35],\n",
       " [97, 35, 21],\n",
       " [97, 35, 21, 26],\n",
       " [97, 35, 21, 26, 20],\n",
       " [97, 35, 21, 26, 20, 98],\n",
       " [97, 35, 21, 26, 20, 98, 37],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99, 6],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7, 28],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7, 28, 100],\n",
       " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7, 28, 100, 101],\n",
       " [15, 22],\n",
       " [15, 22, 3],\n",
       " [15, 22, 3, 52],\n",
       " [15, 22, 3, 52, 6],\n",
       " [15, 22, 3, 52, 6, 53],\n",
       " [15, 22, 3, 52, 6, 53, 16],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54, 7],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54, 7, 1],\n",
       " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54, 7, 1, 16],\n",
       " [23, 12],\n",
       " [23, 12, 24],\n",
       " [23, 12, 24, 13],\n",
       " [23, 12, 24, 13, 37],\n",
       " [23, 12, 24, 13, 37, 102],\n",
       " [23, 12, 24, 13, 37, 102, 103],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8, 105],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8, 105, 106],\n",
       " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8, 105, 106, 21],\n",
       " [23,\n",
       "  12,\n",
       "  24,\n",
       "  13,\n",
       "  37,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  22,\n",
       "  2,\n",
       "  52,\n",
       "  6,\n",
       "  16,\n",
       "  2,\n",
       "  8,\n",
       "  105,\n",
       "  106,\n",
       "  21,\n",
       "  107],\n",
       " [23,\n",
       "  12,\n",
       "  24,\n",
       "  13,\n",
       "  37,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  22,\n",
       "  2,\n",
       "  52,\n",
       "  6,\n",
       "  16,\n",
       "  2,\n",
       "  8,\n",
       "  105,\n",
       "  106,\n",
       "  21,\n",
       "  107,\n",
       "  1],\n",
       " [23,\n",
       "  12,\n",
       "  24,\n",
       "  13,\n",
       "  37,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  22,\n",
       "  2,\n",
       "  52,\n",
       "  6,\n",
       "  16,\n",
       "  2,\n",
       "  8,\n",
       "  105,\n",
       "  106,\n",
       "  21,\n",
       "  107,\n",
       "  1,\n",
       "  54],\n",
       " [29, 8],\n",
       " [29, 8, 3],\n",
       " [29, 8, 3, 108],\n",
       " [29, 8, 3, 108, 1],\n",
       " [29, 8, 3, 108, 1, 55],\n",
       " [29, 8, 3, 108, 1, 55, 109],\n",
       " [110, 28],\n",
       " [110, 28, 39],\n",
       " [110, 28, 39, 111],\n",
       " [110, 28, 39, 111, 5],\n",
       " [110, 28, 39, 111, 5, 40],\n",
       " [110, 28, 39, 111, 5, 40, 56],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57, 56],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112, 7],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112, 7, 1],\n",
       " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112, 7, 1, 17],\n",
       " [15, 11],\n",
       " [15, 11, 1],\n",
       " [15, 11, 1, 58],\n",
       " [15, 11, 1, 58, 33],\n",
       " [15, 11, 1, 58, 33, 7],\n",
       " [15, 11, 1, 58, 33, 7, 12],\n",
       " [15, 11, 1, 58, 33, 7, 12, 1],\n",
       " [15, 11, 1, 58, 33, 7, 12, 1, 53],\n",
       " [15, 11, 1, 58, 33, 7, 12, 1, 53, 13],\n",
       " [113, 12],\n",
       " [113, 12, 1],\n",
       " [113, 12, 1, 13],\n",
       " [113, 12, 1, 13, 114],\n",
       " [113, 12, 1, 13, 114, 115],\n",
       " [113, 12, 1, 13, 114, 115, 116],\n",
       " [113, 12, 1, 13, 114, 115, 116, 117],\n",
       " [15, 11],\n",
       " [15, 11, 1],\n",
       " [15, 11, 1, 118],\n",
       " [15, 11, 1, 118, 119],\n",
       " [15, 11, 1, 118, 119, 57],\n",
       " [15, 11, 1, 118, 119, 57, 1],\n",
       " [15, 11, 1, 118, 119, 57, 1, 120],\n",
       " [15, 11, 1, 118, 119, 57, 1, 120, 121],\n",
       " [15, 11, 1, 118, 119, 57, 1, 120, 121, 1],\n",
       " [15, 11, 1, 118, 119, 57, 1, 120, 121, 1, 13],\n",
       " [123, 4],\n",
       " [123, 4, 3],\n",
       " [123, 4, 3, 18],\n",
       " [123, 4, 3, 18, 124],\n",
       " [123, 4, 3, 18, 124, 45],\n",
       " [123, 4, 3, 18, 124, 45, 1],\n",
       " [123, 4, 3, 18, 124, 45, 1, 125],\n",
       " [123, 4, 3, 18, 124, 45, 1, 125, 55],\n",
       " [2, 4],\n",
       " [2, 4, 38],\n",
       " [2, 4, 38, 6],\n",
       " [2, 4, 38, 6, 59],\n",
       " [2, 4, 38, 6, 59, 60],\n",
       " [2, 4, 38, 6, 59, 60, 24],\n",
       " [2, 4, 38, 6, 59, 60, 24, 126],\n",
       " [2, 4, 38, 6, 59, 60, 24, 126, 127],\n",
       " [2, 4, 38, 6, 59, 60, 24, 126, 127, 128],\n",
       " [2, 4, 38, 6, 59, 60, 24, 126, 127, 128, 129],\n",
       " [2, 4, 38, 6, 59, 60, 24, 126, 127, 128, 129, 16],\n",
       " [8, 3],\n",
       " [8, 3, 41],\n",
       " [8, 3, 41, 28],\n",
       " [8, 3, 41, 28, 17],\n",
       " [8, 3, 41, 28, 17, 22],\n",
       " [8, 3, 41, 28, 17, 22, 3],\n",
       " [8, 3, 41, 28, 17, 22, 3, 61],\n",
       " [8, 3, 41, 28, 17, 22, 3, 61, 60],\n",
       " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6],\n",
       " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6, 130],\n",
       " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6, 130, 131],\n",
       " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6, 130, 131, 132],\n",
       " [23, 62],\n",
       " [3, 61],\n",
       " [3, 61, 63],\n",
       " [3, 61, 63, 8],\n",
       " [3, 61, 63, 8, 3],\n",
       " [3, 61, 63, 8, 3, 30],\n",
       " [3, 61, 63, 8, 3, 30, 1],\n",
       " [3, 61, 63, 8, 3, 30, 1, 10],\n",
       " [3, 61, 63, 8, 3, 30, 1, 10, 9],\n",
       " [3, 61, 63, 8, 3, 30, 1, 10, 9, 1],\n",
       " [3, 61, 63, 8, 3, 30, 1, 10, 9, 1, 64],\n",
       " [62, 2],\n",
       " [62, 2, 8],\n",
       " [62, 2, 8, 30],\n",
       " [62, 2, 8, 30, 1],\n",
       " [62, 2, 8, 30, 1, 10],\n",
       " [62, 2, 8, 30, 1, 10, 133],\n",
       " [22, 3],\n",
       " [22, 3, 30],\n",
       " [22, 3, 30, 65],\n",
       " [22, 3, 30, 65, 9],\n",
       " [22, 3, 30, 65, 9, 1],\n",
       " [22, 3, 30, 65, 9, 1, 64],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12, 1],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12, 1, 31],\n",
       " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12, 1, 31, 134],\n",
       " [23, 135],\n",
       " [23, 135, 2],\n",
       " [23, 135, 2, 67],\n",
       " [23, 135, 2, 67, 1],\n",
       " [23, 135, 2, 67, 1, 136],\n",
       " [23, 135, 2, 67, 1, 136, 2],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137, 9],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137, 9, 42],\n",
       " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137, 9, 42, 68],\n",
       " [29, 41],\n",
       " [29, 41, 3],\n",
       " [29, 41, 3, 14],\n",
       " [29, 41, 3, 14, 5],\n",
       " [29, 41, 3, 14, 5, 69],\n",
       " [29, 41, 3, 14, 5, 69, 1],\n",
       " [29, 41, 3, 14, 5, 69, 1, 43],\n",
       " [2, 138],\n",
       " [2, 138, 14],\n",
       " [2, 138, 14, 5],\n",
       " [2, 138, 14, 5, 69],\n",
       " [2, 138, 14, 5, 69, 1],\n",
       " [2, 138, 14, 5, 69, 1, 43],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5, 141],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5, 141, 142],\n",
       " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5, 141, 142, 1],\n",
       " [2,\n",
       "  138,\n",
       "  14,\n",
       "  5,\n",
       "  69,\n",
       "  1,\n",
       "  43,\n",
       "  25,\n",
       "  4,\n",
       "  139,\n",
       "  2,\n",
       "  27,\n",
       "  1,\n",
       "  140,\n",
       "  2,\n",
       "  14,\n",
       "  5,\n",
       "  141,\n",
       "  142,\n",
       "  1,\n",
       "  43],\n",
       " [2,\n",
       "  138,\n",
       "  14,\n",
       "  5,\n",
       "  69,\n",
       "  1,\n",
       "  43,\n",
       "  25,\n",
       "  4,\n",
       "  139,\n",
       "  2,\n",
       "  27,\n",
       "  1,\n",
       "  140,\n",
       "  2,\n",
       "  14,\n",
       "  5,\n",
       "  141,\n",
       "  142,\n",
       "  1,\n",
       "  43,\n",
       "  143],\n",
       " [4, 25],\n",
       " [4, 25, 41],\n",
       " [4, 25, 41, 36],\n",
       " [4, 25, 41, 36, 50],\n",
       " [4, 25, 41, 36, 50, 9],\n",
       " [4, 25, 41, 36, 50, 9, 1],\n",
       " [4, 25, 41, 36, 50, 9, 1, 10],\n",
       " [29, 8],\n",
       " [29, 8, 25],\n",
       " [29, 8, 25, 70],\n",
       " [29, 8, 25, 70, 2],\n",
       " [2, 8],\n",
       " [2, 8, 59],\n",
       " [2, 8, 59, 144],\n",
       " [2, 8, 59, 144, 145],\n",
       " [2, 8, 59, 144, 145, 146],\n",
       " [2, 8, 59, 144, 145, 146, 71],\n",
       " [2, 8, 59, 144, 145, 146, 71, 147],\n",
       " [2, 14],\n",
       " [2, 14, 5],\n",
       " [2, 14, 5, 67],\n",
       " [2, 14, 5, 67, 12],\n",
       " [2, 14, 5, 67, 12, 42],\n",
       " [2, 14, 5, 67, 12, 42, 148],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151, 19],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151, 19, 24],\n",
       " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151, 19, 24, 72],\n",
       " [2,\n",
       "  14,\n",
       "  5,\n",
       "  67,\n",
       "  12,\n",
       "  42,\n",
       "  148,\n",
       "  149,\n",
       "  44,\n",
       "  24,\n",
       "  72,\n",
       "  150,\n",
       "  11,\n",
       "  1,\n",
       "  151,\n",
       "  19,\n",
       "  24,\n",
       "  72,\n",
       "  152],\n",
       " [2,\n",
       "  14,\n",
       "  5,\n",
       "  67,\n",
       "  12,\n",
       "  42,\n",
       "  148,\n",
       "  149,\n",
       "  44,\n",
       "  24,\n",
       "  72,\n",
       "  150,\n",
       "  11,\n",
       "  1,\n",
       "  151,\n",
       "  19,\n",
       "  24,\n",
       "  72,\n",
       "  152,\n",
       "  153],\n",
       " [2,\n",
       "  14,\n",
       "  5,\n",
       "  67,\n",
       "  12,\n",
       "  42,\n",
       "  148,\n",
       "  149,\n",
       "  44,\n",
       "  24,\n",
       "  72,\n",
       "  150,\n",
       "  11,\n",
       "  1,\n",
       "  151,\n",
       "  19,\n",
       "  24,\n",
       "  72,\n",
       "  152,\n",
       "  153,\n",
       "  71],\n",
       " [2,\n",
       "  14,\n",
       "  5,\n",
       "  67,\n",
       "  12,\n",
       "  42,\n",
       "  148,\n",
       "  149,\n",
       "  44,\n",
       "  24,\n",
       "  72,\n",
       "  150,\n",
       "  11,\n",
       "  1,\n",
       "  151,\n",
       "  19,\n",
       "  24,\n",
       "  72,\n",
       "  152,\n",
       "  153,\n",
       "  71,\n",
       "  9],\n",
       " [29, 8],\n",
       " [29, 8, 3],\n",
       " [29, 8, 3, 154],\n",
       " [29, 8, 3, 154, 155],\n",
       " [29, 8, 3, 154, 155, 9],\n",
       " [29, 8, 3, 154, 155, 9, 36],\n",
       " [29, 8, 3, 154, 155, 9, 36, 7],\n",
       " [29, 8, 3, 154, 155, 9, 36, 7, 6],\n",
       " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32],\n",
       " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32, 156],\n",
       " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32, 156, 1],\n",
       " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32, 156, 1, 16],\n",
       " [2, 4],\n",
       " [2, 4, 14],\n",
       " [2, 4, 14, 5],\n",
       " [2, 4, 14, 5, 157],\n",
       " [2, 4, 14, 5, 157, 6],\n",
       " [2, 4, 14, 5, 157, 6, 39],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70, 2],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70, 2, 19],\n",
       " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70, 2, 19, 6],\n",
       " [2,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  157,\n",
       "  6,\n",
       "  39,\n",
       "  73,\n",
       "  158,\n",
       "  9,\n",
       "  42,\n",
       "  68,\n",
       "  21,\n",
       "  24,\n",
       "  159,\n",
       "  4,\n",
       "  70,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  74],\n",
       " [2,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  157,\n",
       "  6,\n",
       "  39,\n",
       "  73,\n",
       "  158,\n",
       "  9,\n",
       "  42,\n",
       "  68,\n",
       "  21,\n",
       "  24,\n",
       "  159,\n",
       "  4,\n",
       "  70,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  74,\n",
       "  44],\n",
       " [2,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  157,\n",
       "  6,\n",
       "  39,\n",
       "  73,\n",
       "  158,\n",
       "  9,\n",
       "  42,\n",
       "  68,\n",
       "  21,\n",
       "  24,\n",
       "  159,\n",
       "  4,\n",
       "  70,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  74,\n",
       "  44,\n",
       "  74],\n",
       " [2,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  157,\n",
       "  6,\n",
       "  39,\n",
       "  73,\n",
       "  158,\n",
       "  9,\n",
       "  42,\n",
       "  68,\n",
       "  21,\n",
       "  24,\n",
       "  159,\n",
       "  4,\n",
       "  70,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  74,\n",
       "  44,\n",
       "  74,\n",
       "  32],\n",
       " [2,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  157,\n",
       "  6,\n",
       "  39,\n",
       "  73,\n",
       "  158,\n",
       "  9,\n",
       "  42,\n",
       "  68,\n",
       "  21,\n",
       "  24,\n",
       "  159,\n",
       "  4,\n",
       "  70,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  74,\n",
       "  44,\n",
       "  74,\n",
       "  32,\n",
       "  75],\n",
       " [2,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  157,\n",
       "  6,\n",
       "  39,\n",
       "  73,\n",
       "  158,\n",
       "  9,\n",
       "  42,\n",
       "  68,\n",
       "  21,\n",
       "  24,\n",
       "  159,\n",
       "  4,\n",
       "  70,\n",
       "  2,\n",
       "  19,\n",
       "  6,\n",
       "  74,\n",
       "  44,\n",
       "  74,\n",
       "  32,\n",
       "  75,\n",
       "  16],\n",
       " [22, 3],\n",
       " [22, 3, 30],\n",
       " [22, 3, 30, 1],\n",
       " [22, 3, 30, 1, 10],\n",
       " [22, 3, 30, 1, 10, 63],\n",
       " [22, 3, 30, 1, 10, 63, 8],\n",
       " [22, 3, 30, 1, 10, 63, 8, 3],\n",
       " [22, 3, 30, 1, 10, 63, 8, 3, 160],\n",
       " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161],\n",
       " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161, 31],\n",
       " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161, 31, 76],\n",
       " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161, 31, 76, 162],\n",
       " [23, 163],\n",
       " [23, 163, 164],\n",
       " [23, 163, 164, 31],\n",
       " [23, 163, 164, 31, 76],\n",
       " [23, 163, 164, 31, 76, 32],\n",
       " [23, 163, 164, 31, 76, 32, 9],\n",
       " [23, 163, 164, 31, 76, 32, 9, 1],\n",
       " [23, 163, 164, 31, 76, 32, 9, 1, 32],\n",
       " [23, 163, 164, 31, 76, 32, 9, 1, 32, 75],\n",
       " [23, 163, 164, 31, 76, 32, 9, 1, 32, 75, 39],\n",
       " [23, 163, 164, 31, 76, 32, 9, 1, 32, 75, 39, 73],\n",
       " [77, 21],\n",
       " [77, 21, 165],\n",
       " [77, 21, 165, 166],\n",
       " [77, 21, 165, 166, 167],\n",
       " [77, 21, 165, 166, 167, 168],\n",
       " [15, 11],\n",
       " [15, 11, 1],\n",
       " [15, 11, 1, 169],\n",
       " [15, 11, 1, 169, 5],\n",
       " [15, 11, 1, 169, 5, 38],\n",
       " [15, 11, 1, 169, 5, 38, 1],\n",
       " [15, 11, 1, 169, 5, 38, 1, 77],\n",
       " [170, 37],\n",
       " [170, 37, 171],\n",
       " [170, 37, 171, 172],\n",
       " [2, 14],\n",
       " [2, 14, 5],\n",
       " [2, 14, 5, 65],\n",
       " [2, 14, 5, 65, 1],\n",
       " [2, 14, 5, 65, 1, 173],\n",
       " [2, 14, 5, 65, 1, 173, 174],\n",
       " [2, 14],\n",
       " [2, 14, 5],\n",
       " [2, 14, 5, 175],\n",
       " [2, 14, 5, 175, 12],\n",
       " [2, 14, 5, 175, 12, 1],\n",
       " [2, 14, 5, 175, 12, 1, 17],\n",
       " [2, 14, 5, 175, 12, 1, 17, 176],\n",
       " [177, 178],\n",
       " [177, 178, 13],\n",
       " [179, 180],\n",
       " [179, 180, 13],\n",
       " [13, 27],\n",
       " [13, 27, 181],\n",
       " [13, 27, 181, 182],\n",
       " [183, 44],\n",
       " [183, 44, 184],\n",
       " [183, 44, 184, 185],\n",
       " [183, 44, 184, 185, 186]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(x) for x in input_sequence])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_input_seq = pad_sequences(input_sequence, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,  45,   1],\n",
       "       [  0,   0,   0, ...,  45,   1,  10],\n",
       "       [  0,   0,   0, ...,   0,  15,  11],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 183,  44, 184],\n",
       "       [  0,   0,   0, ...,  44, 184, 185],\n",
       "       [  0,   0,   0, ..., 184, 185, 186]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pad_input_seq[:, :-1]\n",
    "y = pad_input_seq[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403, 25)\n",
      "(403,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 200)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=200) #num_classes random\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 25, 100)           20000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               30200     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200800 (784.38 KB)\n",
      "Trainable params: 200800 (784.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(200, 100, input_length=25)) # Same as no.of classes, 100 dense vector, 25 from x.shape\n",
    "#output dense vector of len 100. Means 1 value thave 100 unique number.\n",
    "\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(200, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 5.2554 - accuracy: 0.0819\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.8777 - accuracy: 0.0943\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.7290 - accuracy: 0.0943\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.6768 - accuracy: 0.0943\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.6460 - accuracy: 0.0943\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.6199 - accuracy: 0.0943\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.5763 - accuracy: 0.0943\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.5397 - accuracy: 0.0943\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.4541 - accuracy: 0.0943\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.3778 - accuracy: 0.0968\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.2689 - accuracy: 0.0943\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 4.1603 - accuracy: 0.1216\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 4.0195 - accuracy: 0.1365\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.8778 - accuracy: 0.1663\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 3.7291 - accuracy: 0.1911\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.5796 - accuracy: 0.2184\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.4191 - accuracy: 0.2581\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.2685 - accuracy: 0.2556\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 3.1121 - accuracy: 0.2978\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.9568 - accuracy: 0.3077\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.8110 - accuracy: 0.3350\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.6717 - accuracy: 0.3697\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.5298 - accuracy: 0.4268\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.4033 - accuracy: 0.4417\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 2.2775 - accuracy: 0.4615\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 2.1567 - accuracy: 0.5236\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 2.0328 - accuracy: 0.5558\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.9345 - accuracy: 0.5782\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.8311 - accuracy: 0.6055\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.7268 - accuracy: 0.6402\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.6424 - accuracy: 0.6923\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.5491 - accuracy: 0.7345\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.4602 - accuracy: 0.7444\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.3906 - accuracy: 0.7742\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.3103 - accuracy: 0.7692\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 1.2390 - accuracy: 0.7916\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 1.1816 - accuracy: 0.8114\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.1183 - accuracy: 0.8189\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.0526 - accuracy: 0.8288\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 1.0055 - accuracy: 0.8437\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.9467 - accuracy: 0.8586\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.9035 - accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8544 - accuracy: 0.8809\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.8109 - accuracy: 0.8883\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.7730 - accuracy: 0.8859\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.7387 - accuracy: 0.8933\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.7094 - accuracy: 0.8958\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6771 - accuracy: 0.8983\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6408 - accuracy: 0.9082\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.6096 - accuracy: 0.9057\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5814 - accuracy: 0.9082\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5598 - accuracy: 0.9156\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5407 - accuracy: 0.9206\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.5190 - accuracy: 0.9181\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.4963 - accuracy: 0.9256\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4797 - accuracy: 0.9280\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4593 - accuracy: 0.9256\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4408 - accuracy: 0.9330\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.4245 - accuracy: 0.9355\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.4131 - accuracy: 0.9330\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3972 - accuracy: 0.9305\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3855 - accuracy: 0.9454\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3722 - accuracy: 0.9404\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.3576 - accuracy: 0.9429\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3459 - accuracy: 0.9404\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3391 - accuracy: 0.9355\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3258 - accuracy: 0.9504\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.3186 - accuracy: 0.9429\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.3098 - accuracy: 0.9479\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2992 - accuracy: 0.9429\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2936 - accuracy: 0.9404\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2855 - accuracy: 0.9454\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2789 - accuracy: 0.9380\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2708 - accuracy: 0.9429\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2643 - accuracy: 0.9479\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2616 - accuracy: 0.9429\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2565 - accuracy: 0.9380\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2505 - accuracy: 0.9454\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2436 - accuracy: 0.9404\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2420 - accuracy: 0.9305\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2359 - accuracy: 0.9429\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2283 - accuracy: 0.9479\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2252 - accuracy: 0.9429\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2211 - accuracy: 0.9380\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2194 - accuracy: 0.9404\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2141 - accuracy: 0.9380\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2117 - accuracy: 0.9380\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2059 - accuracy: 0.9429\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2043 - accuracy: 0.9429\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2022 - accuracy: 0.9330\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1972 - accuracy: 0.9404\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1953 - accuracy: 0.9429\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1935 - accuracy: 0.9429\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1905 - accuracy: 0.9404\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1887 - accuracy: 0.9380\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1851 - accuracy: 0.9404\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1852 - accuracy: 0.9380\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1827 - accuracy: 0.9404\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1795 - accuracy: 0.9454\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1776 - accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x123d5b010>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "What is the duration of\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "What is the duration of the\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "What is the duration of the course\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "What is the duration of the course is\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "What is the duration of the course is 16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "text = 'What is the duration'\n",
    "\n",
    "for i in range(5):\n",
    "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "    #Padding \n",
    "    padded_token_text = pad_sequences([token_text], maxlen=25, padding='pre')\n",
    "    #Predict\n",
    "    pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index==pos:\n",
    "            text = text + \" \" + word\n",
    "            print(text)\n",
    "            time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

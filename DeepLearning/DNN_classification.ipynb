{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/datasets/Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Exited'].value_counts()\n",
    "\n",
    "#Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.iloc[:,3:]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Geography','Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into dep and ind variable\n",
    "\n",
    "x = dataset.drop(['Exited'], axis=1) \n",
    "y = dataset[['Exited']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0         7963\n",
      "1         2037\n",
      "dtype: int64\n",
      "Exited\n",
      "0         7963\n",
      "1         7963\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance the data\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "x_smote, y_smote = smote.fit_resample(x, y)\n",
    "print(y.value_counts())\n",
    "print(y_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                384       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32)                128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2305 (9.00 KB)\n",
      "Trainable params: 2145 (8.38 KB)\n",
      "Non-trainable params: 160 (640.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Multi layer preceptron\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer=keras.regularizers.L2(0.03), input_dim=11, kernel_initializer='he_normal'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=keras.regularizers.L2(0.03), kernel_initializer='he_normal'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.17799364, -0.04649976, -0.4151851 , -0.25007302, -0.4608499 ,\n",
       "         -0.09991144,  0.2200182 , -0.8686439 , -0.59024817, -0.5391048 ,\n",
       "         -0.11456428, -0.04013703,  0.6600239 ,  0.3669431 ,  0.05357071,\n",
       "         -0.51938546,  0.43675587,  0.05880391,  0.19791704,  0.02160454,\n",
       "          0.10142463,  0.3180619 ,  0.4014701 ,  0.22905579,  0.28730634,\n",
       "         -0.1499701 , -0.38609082,  0.05044844,  0.66706085, -0.02399244,\n",
       "          0.1663564 , -0.25776443],\n",
       "        [-0.1238649 , -0.42157224,  0.57241213,  0.32832226,  0.74736494,\n",
       "         -0.5546416 ,  0.17521793,  0.81111854,  0.07169497,  0.41348064,\n",
       "         -0.3101607 , -0.46083698, -0.21912478, -0.36179644, -0.43567052,\n",
       "         -0.24620645, -0.18939932, -0.03538012, -0.05220845,  0.05228781,\n",
       "          0.10791662,  0.4827645 ,  0.09149259,  0.43563664,  0.26825845,\n",
       "         -0.7068193 ,  0.8970696 , -0.12943026,  0.40437794,  0.14573373,\n",
       "         -0.12718222, -0.92471915],\n",
       "        [-0.21815887, -0.5048122 ,  0.60326827,  0.3200924 ,  0.61523837,\n",
       "          0.02280132, -0.38156477, -0.43864083, -0.26341245, -0.25957385,\n",
       "          0.29906723,  0.344728  , -0.37711087,  0.09127194,  0.14296988,\n",
       "          0.24132402,  0.01169651, -0.1901099 , -0.09875787, -0.16249366,\n",
       "         -0.16095354,  0.09793025,  0.43988317, -0.04561668, -0.70969594,\n",
       "          0.8597521 , -0.38514906,  0.7759054 ,  0.18781678,  0.2927173 ,\n",
       "          0.73464924, -0.0177373 ],\n",
       "        [ 0.03597979,  0.15525919, -0.58006984,  0.35598665, -0.2523147 ,\n",
       "          0.1273932 , -0.30133924, -0.11932648, -0.22773832,  0.6907175 ,\n",
       "          0.22520515, -0.5801508 , -0.6604004 , -0.3489005 ,  0.61219263,\n",
       "         -0.91992176,  0.34058622, -0.22247824,  0.5262536 , -0.18839078,\n",
       "         -0.7400287 ,  0.12788491, -0.37946188,  0.7679048 ,  0.28274214,\n",
       "          0.35103294,  0.77574587,  0.6991953 ,  0.51324564,  0.5439114 ,\n",
       "         -0.31425694,  0.9173    ],\n",
       "        [-0.5826543 ,  0.03614711,  0.6150912 ,  0.45046374,  0.04076798,\n",
       "          0.49510276, -0.13153249, -0.2049377 ,  0.2892885 , -0.6080382 ,\n",
       "          0.14258976,  0.5326266 ,  0.04915223, -0.26483724,  0.2156024 ,\n",
       "          0.5605506 ,  0.38775095,  0.1872464 , -0.12919806,  0.22583148,\n",
       "         -0.558661  , -0.298913  ,  0.14138192, -0.03693053,  0.27829337,\n",
       "          0.24157357,  0.5418406 , -0.4234086 ,  0.07331106, -0.8542654 ,\n",
       "          0.1808041 , -0.24685702],\n",
       "        [ 0.48206195,  0.25992057,  0.3395762 , -0.33245885,  0.5933832 ,\n",
       "          0.8695061 ,  0.11827021,  0.8291863 , -0.41381276,  0.05799871,\n",
       "         -0.93671584,  0.35450953,  0.22306512, -0.14785856,  0.7697564 ,\n",
       "         -0.91170865, -0.54052526, -0.14425717, -0.31554198, -0.70303625,\n",
       "         -0.40637752,  0.27957347, -0.42155385,  0.19153035,  0.22401322,\n",
       "          0.5847018 , -0.55934817, -0.46507376,  0.49243996, -0.36975566,\n",
       "         -0.1697074 ,  0.881832  ],\n",
       "        [-0.19640312, -0.14569351,  0.27773932, -0.24009632, -0.30797595,\n",
       "          0.08425604,  0.22908548, -0.76890045,  0.5879956 , -0.01270755,\n",
       "          0.21461275,  0.10794862, -0.40153   ,  0.27015454,  0.12301003,\n",
       "          0.3281139 ,  0.15224971,  0.7925889 , -0.20049156,  0.18485449,\n",
       "         -0.560739  ,  0.16430657, -0.08665328,  0.24816819, -0.88760126,\n",
       "         -0.21184264,  0.7462988 , -0.3416196 ,  0.47519654, -0.1974987 ,\n",
       "         -0.2648904 , -0.4567949 ],\n",
       "        [-0.4970423 , -0.07988237,  0.38390565, -0.5109193 , -0.4912123 ,\n",
       "          0.29426667, -0.3603222 , -0.58738893,  0.5928531 , -0.5312374 ,\n",
       "         -0.5529191 ,  0.20457421,  0.4188064 ,  0.43929937, -0.6514656 ,\n",
       "          0.7298191 , -0.0935957 , -0.851097  ,  0.42938736, -0.01504531,\n",
       "         -0.30160585, -0.32626066,  0.20566265,  0.5197553 ,  0.3500239 ,\n",
       "          0.1093102 ,  0.02833138,  0.07060347,  0.24496417, -0.01002221,\n",
       "         -0.11245242, -0.1278287 ],\n",
       "        [-0.82829887,  0.38150594,  0.39341503,  0.6007612 ,  0.04651222,\n",
       "         -0.3305289 ,  0.37442914, -0.28702703, -0.18166494,  0.91328377,\n",
       "         -0.08134705, -0.08734475, -0.9386537 , -0.20917593,  0.24966227,\n",
       "         -0.7162352 ,  0.43171558,  0.34246174, -0.6544287 , -0.6959729 ,\n",
       "         -0.8887724 , -0.72951734,  0.355117  , -0.0809809 , -0.19261916,\n",
       "          0.7841674 , -0.34145728,  0.89237833,  0.89249414, -0.5787824 ,\n",
       "          0.38701886,  0.9047042 ],\n",
       "        [-0.12368549,  0.136566  ,  0.06553915,  0.18461482, -0.6643694 ,\n",
       "          0.31034023,  0.5658308 ,  0.05873469,  0.5995811 , -0.9600572 ,\n",
       "          0.11236187, -0.56038725,  0.7217882 ,  0.02820495,  0.11044386,\n",
       "         -0.3931172 ,  0.5281687 ,  0.45650122,  0.3063744 ,  0.17229384,\n",
       "         -0.6382696 , -0.01112148, -0.27274823, -0.95882505,  0.03460883,\n",
       "          0.42627582, -0.18821993, -0.29100424, -0.61889935,  0.14348681,\n",
       "         -0.46565148, -0.5951518 ],\n",
       "        [ 0.07998078,  0.1720251 ,  0.01636303,  0.26527962, -0.26061362,\n",
       "         -0.09428994,  0.11413199,  0.35720885, -0.18880835,  0.69984335,\n",
       "          0.09130328, -0.60827637,  0.39488778, -0.5845395 ,  0.2713244 ,\n",
       "          0.5797969 ,  0.5952551 , -0.10008688, -0.20623472,  0.10316402,\n",
       "         -0.20986493,  0.4720432 ,  0.32045364,  0.01341951,  0.5179509 ,\n",
       "          0.32028562, -0.17632939, -0.06946999, -0.17672281,  0.5493682 ,\n",
       "         -0.03526118, -0.26489028]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[ 0.38685727,  0.24560149,  0.24770984, ...,  0.3181939 ,\n",
       "         -0.3115487 , -0.10058902],\n",
       "        [ 0.01790579,  0.11786123, -0.25186875, ...,  0.26345813,\n",
       "         -0.37415272,  0.33039004],\n",
       "        [ 0.12054133,  0.33200198, -0.06437071, ..., -0.48307437,\n",
       "          0.03740023,  0.15378687],\n",
       "        ...,\n",
       "        [-0.326042  , -0.17845784, -0.23626502, ...,  0.4886097 ,\n",
       "          0.12119068, -0.4471247 ],\n",
       "        [ 0.19987535,  0.07370064,  0.01976818, ...,  0.44990486,\n",
       "         -0.25492856, -0.38885626],\n",
       "        [-0.20070097, -0.06431682, -0.21582754, ..., -0.06098936,\n",
       "          0.02952748,  0.30387083]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[-2.68959790e-01, -1.89550012e-01,  2.63062894e-01,\n",
       "         -2.60414720e-01,  6.88035712e-02,  3.01531583e-01,\n",
       "         -3.49102646e-01,  4.09813017e-01,  4.05357152e-01,\n",
       "          3.28437388e-01, -1.76205292e-01, -1.11014269e-01,\n",
       "          3.76958609e-01,  4.06950027e-01,  3.53691816e-01,\n",
       "         -2.71758102e-02],\n",
       "        [-4.36206579e-01,  1.60615921e-01,  4.12965454e-02,\n",
       "          4.12433356e-01, -3.46496075e-01,  1.77065089e-01,\n",
       "          1.24346472e-01,  3.32667045e-02, -1.96128309e-01,\n",
       "          1.95440222e-02, -4.79393691e-01,  6.33324087e-02,\n",
       "          9.87576246e-02, -1.90714076e-01,  2.92206734e-01,\n",
       "          3.55046093e-02],\n",
       "        [-4.27861780e-01, -3.08160037e-01,  1.53915942e-01,\n",
       "         -4.28163782e-02, -2.83694237e-01,  4.45024610e-01,\n",
       "          4.22554702e-01,  4.74615842e-02,  2.58135438e-01,\n",
       "         -3.57644558e-01, -4.17421907e-01, -1.43123614e-02,\n",
       "         -2.90038347e-01,  5.65516800e-02,  1.67825967e-01,\n",
       "         -1.03107736e-01],\n",
       "        [-4.22376722e-01,  3.02225530e-01,  1.50681719e-01,\n",
       "          1.76520467e-01,  1.10403515e-01,  3.56799960e-01,\n",
       "         -3.84931028e-01, -3.48247737e-01,  3.29042315e-01,\n",
       "         -3.62568423e-02,  2.08414704e-01, -2.03139752e-01,\n",
       "          2.05419764e-01, -2.53774017e-01,  6.31851256e-02,\n",
       "          1.33714721e-01],\n",
       "        [ 1.05813459e-01,  8.47176835e-03, -1.99809074e-01,\n",
       "          5.24694026e-01,  1.67658001e-01,  5.05607724e-01,\n",
       "         -1.33682147e-01,  2.51747906e-01,  1.31758586e-01,\n",
       "          9.88687724e-02,  2.88063705e-01,  2.05484815e-02,\n",
       "          5.67021780e-02, -2.06641138e-01,  1.03916936e-01,\n",
       "          4.84153152e-01],\n",
       "        [ 4.32863146e-01,  2.70367920e-01,  2.39502117e-01,\n",
       "          1.36598885e-01, -6.21968731e-02,  3.00446469e-02,\n",
       "         -1.93566501e-01, -6.55130595e-02, -4.08781350e-01,\n",
       "          3.65579687e-02, -7.95173943e-02, -4.55194652e-01,\n",
       "         -4.50788319e-01, -5.84937669e-02,  1.95932835e-01,\n",
       "          1.27452403e-01],\n",
       "        [-3.62712026e-01, -3.32785577e-01, -8.59816968e-02,\n",
       "          9.33365226e-02, -3.14231694e-01, -1.79223940e-01,\n",
       "         -3.04619282e-01,  4.94836956e-01,  4.05546427e-01,\n",
       "         -4.19660717e-01, -3.65518741e-02, -1.81624144e-01,\n",
       "         -3.87393892e-01, -2.79861450e-01,  4.96385127e-01,\n",
       "         -3.79766524e-01],\n",
       "        [ 1.93780378e-01, -1.71310216e-01,  5.52271903e-01,\n",
       "         -2.53113005e-02, -4.88307327e-02, -3.45112205e-01,\n",
       "         -2.45009646e-01,  4.87813473e-01, -1.83621496e-01,\n",
       "          5.10708913e-02,  5.78383021e-02, -2.68395007e-01,\n",
       "         -1.96591005e-01, -5.67656577e-01, -2.46806487e-01,\n",
       "         -1.28297389e-01],\n",
       "        [ 1.28137141e-01, -7.77439633e-03,  3.31997037e-01,\n",
       "         -3.92848104e-01, -1.11262545e-01, -3.01715702e-01,\n",
       "          9.46507230e-02,  3.30115288e-01, -2.40116194e-01,\n",
       "          1.23631299e-01, -5.75689273e-03,  3.58778358e-01,\n",
       "          7.73257166e-02, -4.67041075e-01,  2.65878334e-04,\n",
       "         -2.54343394e-02],\n",
       "        [-2.57413715e-01, -2.15776131e-01,  2.11636778e-02,\n",
       "         -3.84704806e-02,  3.97787213e-01, -3.00037950e-01,\n",
       "         -5.14517844e-01,  1.03198685e-01, -2.35096857e-01,\n",
       "          1.15562707e-01,  3.55793297e-01,  4.15758602e-02,\n",
       "          6.14625514e-02,  3.03597093e-01,  1.31084144e-01,\n",
       "         -2.78097630e-01],\n",
       "        [-2.27939829e-01, -6.66150972e-02,  1.66838884e-01,\n",
       "          1.18382098e-02,  2.11900860e-01,  2.73070540e-02,\n",
       "         -1.90117747e-01, -1.04076013e-01, -2.71045744e-01,\n",
       "         -1.36018470e-01, -2.37893790e-01, -3.42951298e-01,\n",
       "          1.08374655e-01,  3.47125679e-02,  1.92339078e-01,\n",
       "         -2.09214017e-02],\n",
       "        [-6.38185740e-02, -8.93527865e-02, -1.18383832e-01,\n",
       "          4.42467183e-01, -1.82633400e-01, -9.30976495e-02,\n",
       "          2.58223295e-01,  3.40844929e-01, -3.58600318e-01,\n",
       "         -1.63559377e-01,  1.07257500e-01, -2.74958927e-02,\n",
       "         -1.09336935e-01,  8.14818684e-03, -4.22189593e-01,\n",
       "         -5.11555493e-01],\n",
       "        [ 2.80243099e-01, -2.10851610e-01, -2.01699510e-01,\n",
       "         -3.59175622e-01, -2.08347619e-01, -3.43327522e-01,\n",
       "         -4.35938656e-01,  4.85628471e-02,  1.17710028e-02,\n",
       "          2.00261116e-01,  3.08037430e-01, -5.16283929e-01,\n",
       "         -4.50395979e-02,  2.79855371e-01, -2.29919210e-01,\n",
       "          8.71237889e-02],\n",
       "        [ 2.11144030e-01, -1.74445122e-01,  4.31136489e-02,\n",
       "          1.74801067e-01, -5.04624583e-02, -1.51192725e-01,\n",
       "         -2.14308485e-01, -3.59616637e-01, -1.56332910e-01,\n",
       "          4.85344917e-01, -1.49026632e-01, -3.20728263e-03,\n",
       "          9.03777331e-02,  3.42512578e-01,  5.59464693e-01,\n",
       "          1.24011390e-01],\n",
       "        [-9.87314880e-02,  1.90680586e-02, -5.58114834e-02,\n",
       "          6.18699193e-02,  4.41830903e-01,  9.44575220e-02,\n",
       "         -4.60477382e-01, -1.20056570e-02, -1.26895711e-01,\n",
       "         -3.30643028e-01,  6.34043440e-02, -7.44273886e-03,\n",
       "         -4.07396853e-01, -1.30360737e-01, -1.19051337e-01,\n",
       "         -1.56868964e-01],\n",
       "        [-1.40015790e-02, -3.60178411e-01,  2.09448449e-02,\n",
       "          4.50760901e-01, -3.06862351e-02,  1.82611555e-01,\n",
       "          5.12491465e-01, -1.55197248e-01, -1.03744809e-02,\n",
       "         -4.66969796e-02, -2.17819195e-02, -2.58372843e-01,\n",
       "         -1.84179172e-02, -2.41988346e-01,  2.25582168e-01,\n",
       "         -6.45625219e-02],\n",
       "        [-1.24633037e-01, -1.20335914e-01, -2.58351088e-01,\n",
       "         -3.45534444e-01, -2.71658093e-01, -4.72750396e-01,\n",
       "          4.03253645e-01,  2.51747787e-01, -5.29369950e-01,\n",
       "          3.37542683e-01, -4.84618008e-01,  9.45766941e-02,\n",
       "         -8.55282992e-02,  3.70066881e-01, -1.71755806e-01,\n",
       "         -1.30969197e-01],\n",
       "        [-5.98993637e-02, -1.78439647e-01, -1.43591926e-01,\n",
       "         -2.32946306e-01, -1.33461922e-01, -1.06310574e-02,\n",
       "         -2.00968593e-01,  1.76407024e-01, -4.77643102e-01,\n",
       "         -4.26242918e-01, -1.27525374e-01, -9.59794149e-02,\n",
       "          1.14866890e-01, -2.70168751e-01, -4.06627171e-02,\n",
       "          2.56338120e-01],\n",
       "        [ 1.58808365e-01,  1.51638621e-02, -1.22988895e-01,\n",
       "         -6.21043928e-02,  2.36053705e-01,  2.19413131e-01,\n",
       "         -1.76132441e-01,  3.52401346e-01,  3.90386462e-01,\n",
       "          5.97660467e-02,  3.32558975e-02, -3.36204171e-01,\n",
       "         -4.30351049e-01, -1.77799970e-01, -8.08318928e-02,\n",
       "          4.12888564e-02],\n",
       "        [ 1.95399553e-01,  4.33215320e-01,  5.01408540e-02,\n",
       "          1.92493498e-01,  7.10366964e-02,  4.79273885e-01,\n",
       "          3.95519614e-01, -3.15491796e-01,  4.02425438e-01,\n",
       "          2.29855031e-01,  2.67561883e-01,  3.00674438e-01,\n",
       "          7.80371353e-02,  7.27492124e-02,  1.14264876e-01,\n",
       "         -4.59607631e-01],\n",
       "        [-2.05553427e-01, -2.53486574e-01, -5.81521615e-02,\n",
       "         -1.96144693e-02, -1.14948906e-01,  3.30952764e-01,\n",
       "         -2.99678147e-02, -9.79580507e-02,  2.50673667e-02,\n",
       "          8.25963840e-02, -1.45749286e-01, -4.34318602e-01,\n",
       "          7.08828419e-02,  1.09444782e-01, -1.85219087e-02,\n",
       "          5.10191137e-04],\n",
       "        [ 2.87163049e-01,  1.59454986e-01,  2.86369503e-01,\n",
       "          7.76534006e-02, -9.81493145e-02, -7.37264529e-02,\n",
       "         -4.17574972e-01, -1.69938534e-01,  2.18687251e-01,\n",
       "          5.20174801e-01,  2.38669440e-01, -2.24343330e-01,\n",
       "         -2.57777125e-01, -1.97445750e-01,  2.19396695e-01,\n",
       "         -1.64369702e-01],\n",
       "        [-1.37458503e-01,  3.40748839e-02,  1.83452412e-01,\n",
       "         -2.10244715e-01, -3.59660178e-01,  6.88442364e-02,\n",
       "         -4.05154318e-01, -4.85647231e-01, -1.04421973e-02,\n",
       "          6.91616461e-02,  2.57725775e-01,  1.70356154e-01,\n",
       "          2.24223226e-01, -2.34559745e-01,  3.14369559e-01,\n",
       "          3.69660705e-01],\n",
       "        [-1.97793812e-01,  1.55315980e-01,  1.98088273e-01,\n",
       "          3.75969231e-01, -1.14607468e-01,  3.44390050e-02,\n",
       "          3.04964811e-01, -4.63104956e-02,  1.87209132e-03,\n",
       "          8.38057045e-03, -4.41391319e-01, -3.33921090e-02,\n",
       "         -1.37038782e-01,  4.94254440e-01, -1.89066470e-01,\n",
       "          6.61664531e-02],\n",
       "        [ 1.45301059e-01,  6.30166531e-02, -5.43215908e-02,\n",
       "         -1.23642877e-01, -2.42243946e-01,  4.60654169e-01,\n",
       "         -5.09352684e-01, -3.79065350e-02,  1.70584857e-01,\n",
       "          4.22559649e-01, -3.71003032e-01,  1.14977702e-01,\n",
       "         -1.47980884e-01, -2.36717939e-01,  2.75551885e-01,\n",
       "         -2.11585954e-01],\n",
       "        [-8.49682540e-02,  1.89043105e-01,  2.74419785e-01,\n",
       "         -2.84428775e-01,  8.16949233e-02,  2.24617094e-01,\n",
       "          1.17044978e-01,  4.72029537e-01, -3.33903342e-01,\n",
       "         -3.59197915e-01, -2.45008796e-01,  8.05022120e-02,\n",
       "          1.41519383e-01,  4.68474030e-01,  1.91640764e-01,\n",
       "         -1.60915434e-01],\n",
       "        [ 7.54164830e-02, -4.50860173e-01,  2.99352050e-01,\n",
       "         -3.29802692e-01,  9.13214982e-02,  2.99671650e-01,\n",
       "          1.88135132e-01, -1.94928929e-01,  1.84830382e-01,\n",
       "          4.48809713e-01, -2.46234313e-01, -1.98421371e-03,\n",
       "         -3.86679262e-01,  2.09121332e-01, -2.85894185e-01,\n",
       "          3.63677949e-01],\n",
       "        [ 2.65862912e-01,  2.29121745e-01, -1.69155806e-01,\n",
       "         -2.47749597e-01,  3.11395496e-01, -1.54396296e-01,\n",
       "          1.75390944e-01,  3.95319670e-01,  2.69335955e-01,\n",
       "         -1.15604706e-01,  4.45536673e-02, -2.18131259e-01,\n",
       "          8.12794268e-03,  1.28243980e-03,  5.62726557e-01,\n",
       "          1.89872429e-01],\n",
       "        [ 4.67412055e-01, -4.34870631e-01, -2.92684525e-01,\n",
       "          3.69664729e-01,  2.41819501e-01, -4.41479981e-01,\n",
       "         -8.24875385e-02,  7.45786726e-02,  1.55920908e-01,\n",
       "         -7.53326863e-02,  2.63633400e-01,  1.09318078e-01,\n",
       "         -4.28373843e-01, -6.78215781e-03, -1.61652341e-02,\n",
       "          3.73567897e-03],\n",
       "        [-1.83291256e-01, -1.12453356e-01, -5.91015741e-02,\n",
       "          1.91148728e-01,  2.66641468e-01, -2.85217822e-01,\n",
       "          2.89439797e-01,  6.00098446e-02,  5.90657033e-02,\n",
       "         -1.55433759e-01, -1.15284167e-01,  2.53213525e-01,\n",
       "         -3.66143613e-05,  2.87983060e-01,  1.86558560e-01,\n",
       "          3.03740025e-01],\n",
       "        [ 1.97159901e-01,  3.01893204e-01,  1.83636490e-02,\n",
       "         -1.86784893e-01,  2.78721869e-01, -5.36962189e-02,\n",
       "         -5.57709597e-02, -2.31312320e-01, -4.93956983e-01,\n",
       "         -1.71698645e-01,  2.31848173e-02,  1.84310690e-01,\n",
       "         -1.77734673e-01, -1.83966145e-01, -5.51991463e-02,\n",
       "         -1.31810084e-01],\n",
       "        [-1.36098325e-01,  8.70260969e-03,  4.28038202e-02,\n",
       "         -3.02306324e-01,  5.44665933e-01,  4.11745131e-01,\n",
       "          2.31223665e-02, -3.37186158e-01, -1.31941006e-01,\n",
       "         -3.59080046e-01, -9.65178832e-02,  3.24760318e-01,\n",
       "         -4.20268774e-01, -9.57470536e-02, -3.42958480e-01,\n",
       "          3.86544496e-01]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[-0.23051542],\n",
       "        [-0.5133076 ],\n",
       "        [-0.09063667],\n",
       "        [-0.54470557],\n",
       "        [ 0.04501444],\n",
       "        [ 0.5395335 ],\n",
       "        [ 0.48367143],\n",
       "        [-0.4191743 ],\n",
       "        [-0.5460404 ],\n",
       "        [ 0.12954015],\n",
       "        [-0.08963358],\n",
       "        [ 0.51598334],\n",
       "        [-0.05576646],\n",
       "        [-0.3934305 ],\n",
       "        [-0.24634787],\n",
       "        [-0.26818478]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "374/374 [==============================] - 1s 839us/step - loss: 3.3212 - accuracy: 0.7328 - val_loss: 1.8280 - val_accuracy: 0.7614\n",
      "Epoch 2/100\n",
      "374/374 [==============================] - 0s 621us/step - loss: 1.2149 - accuracy: 0.7982 - val_loss: 0.8353 - val_accuracy: 0.8137\n",
      "Epoch 3/100\n",
      "374/374 [==============================] - 0s 597us/step - loss: 0.6867 - accuracy: 0.8119 - val_loss: 0.5845 - val_accuracy: 0.8106\n",
      "Epoch 4/100\n",
      "374/374 [==============================] - 0s 596us/step - loss: 0.5239 - accuracy: 0.8183 - val_loss: 0.4925 - val_accuracy: 0.8157\n",
      "Epoch 5/100\n",
      "374/374 [==============================] - 0s 587us/step - loss: 0.4683 - accuracy: 0.8215 - val_loss: 0.4549 - val_accuracy: 0.8282\n",
      "Epoch 6/100\n",
      "374/374 [==============================] - 0s 598us/step - loss: 0.4508 - accuracy: 0.8212 - val_loss: 0.4342 - val_accuracy: 0.8285\n",
      "Epoch 7/100\n",
      "374/374 [==============================] - 0s 647us/step - loss: 0.4374 - accuracy: 0.8206 - val_loss: 0.4248 - val_accuracy: 0.8214\n",
      "Epoch 8/100\n",
      "374/374 [==============================] - 0s 596us/step - loss: 0.4331 - accuracy: 0.8224 - val_loss: 0.4139 - val_accuracy: 0.8262\n",
      "Epoch 9/100\n",
      "374/374 [==============================] - 0s 597us/step - loss: 0.4226 - accuracy: 0.8221 - val_loss: 0.4145 - val_accuracy: 0.8257\n",
      "Epoch 10/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.4238 - accuracy: 0.8204 - val_loss: 0.4170 - val_accuracy: 0.8265\n",
      "Epoch 11/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.4201 - accuracy: 0.8241 - val_loss: 0.4165 - val_accuracy: 0.8202\n",
      "Epoch 12/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.4181 - accuracy: 0.8230 - val_loss: 0.4065 - val_accuracy: 0.8237\n",
      "Epoch 13/100\n",
      "374/374 [==============================] - 0s 612us/step - loss: 0.4159 - accuracy: 0.8251 - val_loss: 0.4150 - val_accuracy: 0.8260\n",
      "Epoch 14/100\n",
      "374/374 [==============================] - 0s 602us/step - loss: 0.4119 - accuracy: 0.8240 - val_loss: 0.4089 - val_accuracy: 0.8235\n",
      "Epoch 15/100\n",
      "374/374 [==============================] - 0s 642us/step - loss: 0.4097 - accuracy: 0.8301 - val_loss: 0.4217 - val_accuracy: 0.8194\n",
      "Epoch 16/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.4085 - accuracy: 0.8270 - val_loss: 0.4112 - val_accuracy: 0.8257\n",
      "Epoch 17/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.4092 - accuracy: 0.8259 - val_loss: 0.3994 - val_accuracy: 0.8235\n",
      "Epoch 18/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.4072 - accuracy: 0.8260 - val_loss: 0.4090 - val_accuracy: 0.8192\n",
      "Epoch 19/100\n",
      "374/374 [==============================] - 0s 597us/step - loss: 0.4070 - accuracy: 0.8242 - val_loss: 0.3986 - val_accuracy: 0.8272\n",
      "Epoch 20/100\n",
      "374/374 [==============================] - 0s 601us/step - loss: 0.4060 - accuracy: 0.8283 - val_loss: 0.4063 - val_accuracy: 0.8230\n",
      "Epoch 21/100\n",
      "374/374 [==============================] - 0s 600us/step - loss: 0.4022 - accuracy: 0.8307 - val_loss: 0.4104 - val_accuracy: 0.8212\n",
      "Epoch 22/100\n",
      "374/374 [==============================] - 0s 600us/step - loss: 0.4014 - accuracy: 0.8319 - val_loss: 0.4026 - val_accuracy: 0.8267\n",
      "Epoch 23/100\n",
      "374/374 [==============================] - 0s 600us/step - loss: 0.4014 - accuracy: 0.8294 - val_loss: 0.4027 - val_accuracy: 0.8307\n",
      "Epoch 24/100\n",
      "374/374 [==============================] - 0s 600us/step - loss: 0.4036 - accuracy: 0.8294 - val_loss: 0.3914 - val_accuracy: 0.8390\n",
      "Epoch 25/100\n",
      "374/374 [==============================] - 0s 649us/step - loss: 0.4009 - accuracy: 0.8322 - val_loss: 0.3932 - val_accuracy: 0.8305\n",
      "Epoch 26/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.4055 - accuracy: 0.8313 - val_loss: 0.3956 - val_accuracy: 0.8312\n",
      "Epoch 27/100\n",
      "374/374 [==============================] - 0s 598us/step - loss: 0.4029 - accuracy: 0.8298 - val_loss: 0.4024 - val_accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "374/374 [==============================] - 0s 584us/step - loss: 0.4029 - accuracy: 0.8310 - val_loss: 0.4029 - val_accuracy: 0.8267\n",
      "Epoch 29/100\n",
      "374/374 [==============================] - 0s 587us/step - loss: 0.4004 - accuracy: 0.8327 - val_loss: 0.4020 - val_accuracy: 0.8192\n",
      "Epoch 30/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3961 - accuracy: 0.8331 - val_loss: 0.3932 - val_accuracy: 0.8312\n",
      "Epoch 31/100\n",
      "374/374 [==============================] - 0s 615us/step - loss: 0.3973 - accuracy: 0.8328 - val_loss: 0.4071 - val_accuracy: 0.8267\n",
      "Epoch 32/100\n",
      "374/374 [==============================] - 0s 593us/step - loss: 0.3972 - accuracy: 0.8317 - val_loss: 0.3941 - val_accuracy: 0.8287\n",
      "Epoch 33/100\n",
      "374/374 [==============================] - 0s 592us/step - loss: 0.4021 - accuracy: 0.8305 - val_loss: 0.3942 - val_accuracy: 0.8275\n",
      "Epoch 34/100\n",
      "374/374 [==============================] - 0s 599us/step - loss: 0.3972 - accuracy: 0.8302 - val_loss: 0.3961 - val_accuracy: 0.8282\n",
      "Epoch 35/100\n",
      "374/374 [==============================] - 0s 600us/step - loss: 0.3961 - accuracy: 0.8335 - val_loss: 0.3984 - val_accuracy: 0.8348\n",
      "Epoch 36/100\n",
      "374/374 [==============================] - 0s 647us/step - loss: 0.3961 - accuracy: 0.8289 - val_loss: 0.3946 - val_accuracy: 0.8277\n",
      "Epoch 37/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3955 - accuracy: 0.8341 - val_loss: 0.3918 - val_accuracy: 0.8320\n",
      "Epoch 38/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.4000 - accuracy: 0.8300 - val_loss: 0.4031 - val_accuracy: 0.8290\n",
      "Epoch 39/100\n",
      "374/374 [==============================] - 0s 601us/step - loss: 0.3972 - accuracy: 0.8310 - val_loss: 0.3932 - val_accuracy: 0.8262\n",
      "Epoch 40/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3973 - accuracy: 0.8359 - val_loss: 0.3946 - val_accuracy: 0.8280\n",
      "Epoch 41/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3962 - accuracy: 0.8339 - val_loss: 0.3939 - val_accuracy: 0.8292\n",
      "Epoch 42/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3988 - accuracy: 0.8297 - val_loss: 0.3978 - val_accuracy: 0.8305\n",
      "Epoch 43/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.3997 - accuracy: 0.8281 - val_loss: 0.3926 - val_accuracy: 0.8290\n",
      "Epoch 44/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.3971 - accuracy: 0.8300 - val_loss: 0.3909 - val_accuracy: 0.8317\n",
      "Epoch 45/100\n",
      "374/374 [==============================] - 0s 600us/step - loss: 0.3957 - accuracy: 0.8326 - val_loss: 0.3918 - val_accuracy: 0.8343\n",
      "Epoch 46/100\n",
      "374/374 [==============================] - 0s 602us/step - loss: 0.3926 - accuracy: 0.8346 - val_loss: 0.3995 - val_accuracy: 0.8235\n",
      "Epoch 47/100\n",
      "374/374 [==============================] - 0s 649us/step - loss: 0.3964 - accuracy: 0.8299 - val_loss: 0.3906 - val_accuracy: 0.8338\n",
      "Epoch 48/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3955 - accuracy: 0.8343 - val_loss: 0.3998 - val_accuracy: 0.8307\n",
      "Epoch 49/100\n",
      "374/374 [==============================] - 0s 590us/step - loss: 0.3937 - accuracy: 0.8334 - val_loss: 0.3934 - val_accuracy: 0.8280\n",
      "Epoch 50/100\n",
      "374/374 [==============================] - 0s 599us/step - loss: 0.3979 - accuracy: 0.8300 - val_loss: 0.3957 - val_accuracy: 0.8272\n",
      "Epoch 51/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3951 - accuracy: 0.8295 - val_loss: 0.3896 - val_accuracy: 0.8315\n",
      "Epoch 52/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.3940 - accuracy: 0.8320 - val_loss: 0.3914 - val_accuracy: 0.8295\n",
      "Epoch 53/100\n",
      "374/374 [==============================] - 0s 608us/step - loss: 0.3961 - accuracy: 0.8279 - val_loss: 0.3908 - val_accuracy: 0.8257\n",
      "Epoch 54/100\n",
      "374/374 [==============================] - 0s 609us/step - loss: 0.3960 - accuracy: 0.8300 - val_loss: 0.3924 - val_accuracy: 0.8335\n",
      "Epoch 55/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3947 - accuracy: 0.8300 - val_loss: 0.3964 - val_accuracy: 0.8285\n",
      "Epoch 56/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3964 - accuracy: 0.8339 - val_loss: 0.3911 - val_accuracy: 0.8320\n",
      "Epoch 57/100\n",
      "374/374 [==============================] - 0s 643us/step - loss: 0.3907 - accuracy: 0.8351 - val_loss: 0.3906 - val_accuracy: 0.8312\n",
      "Epoch 58/100\n",
      "374/374 [==============================] - 0s 607us/step - loss: 0.3966 - accuracy: 0.8354 - val_loss: 0.3998 - val_accuracy: 0.8310\n",
      "Epoch 59/100\n",
      "374/374 [==============================] - 0s 608us/step - loss: 0.3890 - accuracy: 0.8314 - val_loss: 0.3923 - val_accuracy: 0.8285\n",
      "Epoch 60/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3961 - accuracy: 0.8302 - val_loss: 0.3915 - val_accuracy: 0.8345\n",
      "Epoch 61/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3931 - accuracy: 0.8311 - val_loss: 0.3942 - val_accuracy: 0.8275\n",
      "Epoch 62/100\n",
      "374/374 [==============================] - 0s 620us/step - loss: 0.3955 - accuracy: 0.8313 - val_loss: 0.4000 - val_accuracy: 0.8310\n",
      "Epoch 63/100\n",
      "374/374 [==============================] - 0s 603us/step - loss: 0.3911 - accuracy: 0.8341 - val_loss: 0.3884 - val_accuracy: 0.8325\n",
      "Epoch 64/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.3945 - accuracy: 0.8341 - val_loss: 0.3937 - val_accuracy: 0.8330\n",
      "Epoch 65/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.3926 - accuracy: 0.8307 - val_loss: 0.3860 - val_accuracy: 0.8340\n",
      "Epoch 66/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3945 - accuracy: 0.8312 - val_loss: 0.3983 - val_accuracy: 0.8295\n",
      "Epoch 67/100\n",
      "374/374 [==============================] - 0s 607us/step - loss: 0.3933 - accuracy: 0.8303 - val_loss: 0.3967 - val_accuracy: 0.8265\n",
      "Epoch 68/100\n",
      "374/374 [==============================] - 0s 602us/step - loss: 0.3934 - accuracy: 0.8316 - val_loss: 0.3952 - val_accuracy: 0.8300\n",
      "Epoch 69/100\n",
      "374/374 [==============================] - 0s 648us/step - loss: 0.3928 - accuracy: 0.8330 - val_loss: 0.3908 - val_accuracy: 0.8315\n",
      "Epoch 70/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3908 - accuracy: 0.8338 - val_loss: 0.3993 - val_accuracy: 0.8285\n",
      "Epoch 71/100\n",
      "374/374 [==============================] - 0s 608us/step - loss: 0.3929 - accuracy: 0.8352 - val_loss: 0.3894 - val_accuracy: 0.8312\n",
      "Epoch 72/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3958 - accuracy: 0.8284 - val_loss: 0.3925 - val_accuracy: 0.8295\n",
      "Epoch 73/100\n",
      "374/374 [==============================] - 0s 609us/step - loss: 0.3929 - accuracy: 0.8341 - val_loss: 0.3918 - val_accuracy: 0.8290\n",
      "Epoch 74/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3913 - accuracy: 0.8347 - val_loss: 0.3900 - val_accuracy: 0.8307\n",
      "Epoch 75/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3936 - accuracy: 0.8331 - val_loss: 0.3939 - val_accuracy: 0.8282\n",
      "Epoch 76/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3912 - accuracy: 0.8351 - val_loss: 0.3987 - val_accuracy: 0.8252\n",
      "Epoch 77/100\n",
      "374/374 [==============================] - 0s 609us/step - loss: 0.3962 - accuracy: 0.8296 - val_loss: 0.3971 - val_accuracy: 0.8257\n",
      "Epoch 78/100\n",
      "374/374 [==============================] - 0s 609us/step - loss: 0.3918 - accuracy: 0.8362 - val_loss: 0.3977 - val_accuracy: 0.8267\n",
      "Epoch 79/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3930 - accuracy: 0.8315 - val_loss: 0.3927 - val_accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "374/374 [==============================] - 0s 653us/step - loss: 0.3926 - accuracy: 0.8327 - val_loss: 0.4084 - val_accuracy: 0.8250\n",
      "Epoch 81/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3955 - accuracy: 0.8301 - val_loss: 0.3942 - val_accuracy: 0.8315\n",
      "Epoch 82/100\n",
      "374/374 [==============================] - 0s 585us/step - loss: 0.3906 - accuracy: 0.8336 - val_loss: 0.3936 - val_accuracy: 0.8287\n",
      "Epoch 83/100\n",
      "374/374 [==============================] - 0s 608us/step - loss: 0.3937 - accuracy: 0.8330 - val_loss: 0.3959 - val_accuracy: 0.8255\n",
      "Epoch 84/100\n",
      "374/374 [==============================] - 0s 609us/step - loss: 0.3909 - accuracy: 0.8364 - val_loss: 0.3948 - val_accuracy: 0.8310\n",
      "Epoch 85/100\n",
      "374/374 [==============================] - 0s 597us/step - loss: 0.3931 - accuracy: 0.8300 - val_loss: 0.3916 - val_accuracy: 0.8222\n",
      "Epoch 86/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3964 - accuracy: 0.8275 - val_loss: 0.3903 - val_accuracy: 0.8325\n",
      "Epoch 87/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3943 - accuracy: 0.8330 - val_loss: 0.4017 - val_accuracy: 0.8242\n",
      "Epoch 88/100\n",
      "374/374 [==============================] - 0s 607us/step - loss: 0.3946 - accuracy: 0.8339 - val_loss: 0.4046 - val_accuracy: 0.8250\n",
      "Epoch 89/100\n",
      "374/374 [==============================] - 0s 651us/step - loss: 0.3914 - accuracy: 0.8336 - val_loss: 0.3914 - val_accuracy: 0.8332\n",
      "Epoch 90/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.3933 - accuracy: 0.8312 - val_loss: 0.3937 - val_accuracy: 0.8242\n",
      "Epoch 91/100\n",
      "374/374 [==============================] - 0s 601us/step - loss: 0.3929 - accuracy: 0.8317 - val_loss: 0.3899 - val_accuracy: 0.8330\n",
      "Epoch 92/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.3935 - accuracy: 0.8334 - val_loss: 0.3970 - val_accuracy: 0.8275\n",
      "Epoch 93/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3942 - accuracy: 0.8324 - val_loss: 0.3978 - val_accuracy: 0.8232\n",
      "Epoch 94/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.3914 - accuracy: 0.8329 - val_loss: 0.3986 - val_accuracy: 0.8265\n",
      "Epoch 95/100\n",
      "374/374 [==============================] - 0s 605us/step - loss: 0.3929 - accuracy: 0.8326 - val_loss: 0.3936 - val_accuracy: 0.8340\n",
      "Epoch 96/100\n",
      "374/374 [==============================] - 0s 604us/step - loss: 0.3917 - accuracy: 0.8337 - val_loss: 0.3975 - val_accuracy: 0.8287\n",
      "Epoch 97/100\n",
      "374/374 [==============================] - 0s 606us/step - loss: 0.3933 - accuracy: 0.8310 - val_loss: 0.3964 - val_accuracy: 0.8232\n",
      "Epoch 98/100\n",
      "374/374 [==============================] - 0s 610us/step - loss: 0.3942 - accuracy: 0.8339 - val_loss: 0.3977 - val_accuracy: 0.8295\n",
      "Epoch 99/100\n",
      "374/374 [==============================] - 0s 650us/step - loss: 0.3952 - accuracy: 0.8273 - val_loss: 0.3925 - val_accuracy: 0.8287\n",
      "Epoch 100/100\n",
      "374/374 [==============================] - 0s 611us/step - loss: 0.3916 - accuracy: 0.8345 - val_loss: 0.3916 - val_accuracy: 0.8287\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dropout and batch normalization, etc to check model score improvements\n",
    "# Multi layer preceptron\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu',kernel_regularizer=keras.regularizers.L2(0.03), input_dim=11, kernel_initializer='he_normal'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(32, activation='relu', kernel_regularizer=keras.regularizers.L2(0.03), kernel_initializer='he_normal'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 300us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.60661435],\n",
       "       [0.6633061 ],\n",
       "       [0.8036168 ],\n",
       "       ...,\n",
       "       [0.7657363 ],\n",
       "       [0.18595271],\n",
       "       [0.46575156]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5182939962486581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimization method\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu',input_dim=11))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "import time\n",
    "from datetime import datetime, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=11944, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schostic GD\n",
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, batch_size=1, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

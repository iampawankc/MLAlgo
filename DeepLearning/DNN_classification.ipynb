{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('/Users/pawankumarkc/Documents/vscode_workspace/MLAlgo/datasets/Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Exited'].value_counts()\n",
    "\n",
    "#Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.iloc[:,3:]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Geography','Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into dep and ind variable\n",
    "\n",
    "x = dataset.drop(['Exited'], axis=1) \n",
    "y = dataset[['Exited']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0         7963\n",
      "1         2037\n",
      "dtype: int64\n",
      "Exited\n",
      "0         7963\n",
      "1         7963\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance the data\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "x_smote, y_smote = smote.fit_resample(x, y)\n",
    "print(y.value_counts())\n",
    "print(y_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_smote, y_smote, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 32)                384       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1729 (6.75 KB)\n",
      "Trainable params: 1601 (6.25 KB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Multi layer preceptron\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer=keras.regularizers.L2(0.03), input_dim=11, kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=keras.regularizers.L2(0.03), kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04503708, -0.6734913 ,  0.678027  , -0.49905542, -0.31851572,\n",
       "          0.796708  , -0.14913155, -0.58703357,  0.51083094, -0.45684192,\n",
       "          0.1533386 , -0.4644907 , -0.4435257 , -0.608214  ,  0.00346696,\n",
       "         -0.4436048 , -0.75879055,  0.10924438, -0.3491522 , -0.9213422 ,\n",
       "          0.68189335,  0.78235763, -0.0838723 , -0.00746389, -0.30139804,\n",
       "         -0.40382287,  0.3115964 ,  0.01014484,  0.5991299 , -0.1468734 ,\n",
       "          0.20460491, -0.76793474],\n",
       "        [-0.66952085,  0.65255094, -0.6798052 ,  0.21515581, -0.7898342 ,\n",
       "          0.26504737,  0.06494351, -0.40577775,  0.21561325, -0.5422905 ,\n",
       "         -0.29254603,  0.6956811 , -0.06266653,  0.32070553, -0.32673153,\n",
       "         -0.20136395,  0.24442363,  0.7540886 ,  0.09994335,  0.09731679,\n",
       "         -0.4288791 ,  0.26053378,  0.8079847 ,  0.31594422, -0.2237311 ,\n",
       "         -0.73279786, -0.53164554, -0.16122301, -0.439185  , -0.3153363 ,\n",
       "          0.44520608, -0.12606539],\n",
       "        [ 0.08316143,  0.46590757, -0.9161116 ,  0.1348357 ,  0.2738989 ,\n",
       "         -0.5034381 , -0.7458751 ,  0.24292582, -0.66533273, -0.26494193,\n",
       "         -0.7894291 , -0.53366107, -0.7427902 , -0.5893145 , -0.12977841,\n",
       "          0.15416335, -0.5589824 , -0.12246848, -0.7646969 , -0.57552123,\n",
       "          0.609639  ,  0.25168657,  0.4420421 ,  0.3006329 ,  0.1336338 ,\n",
       "         -0.4161391 ,  0.2659948 ,  0.32622623, -0.89028054, -0.16598842,\n",
       "         -0.43042988,  0.10750517],\n",
       "        [ 0.8853183 ,  0.7761351 , -0.16979846,  0.7505435 , -0.07757971,\n",
       "          0.20979288, -0.46896836,  0.90036   ,  0.24685031,  0.30731228,\n",
       "         -0.35900667,  0.47216895,  0.1219859 ,  0.49916005,  0.14346577,\n",
       "          0.18317804,  0.23879632,  0.15713467,  0.05370775,  0.16501926,\n",
       "         -0.07860194, -0.70704216,  0.5757253 ,  0.03692511, -0.80063605,\n",
       "         -0.80150366,  0.82563126,  0.36449537, -0.28863332, -0.40009156,\n",
       "         -0.37638128, -0.08634762],\n",
       "        [ 0.17691365,  0.7731209 , -0.24397847, -0.03504561,  0.08427876,\n",
       "          0.3620437 ,  0.07778749,  0.4230357 ,  0.36321795,  0.6399226 ,\n",
       "         -0.6402345 , -0.6601932 , -0.3321783 , -0.09700817, -0.5160188 ,\n",
       "         -0.3668873 ,  0.21101385, -0.20097207,  0.3378914 ,  0.03994144,\n",
       "         -0.38846725, -0.36549777,  0.34626856, -0.66210896, -0.38858232,\n",
       "         -0.04787189,  0.59563226,  0.01153943,  0.17619622,  0.03475136,\n",
       "          0.17975397, -0.7316172 ],\n",
       "        [-0.5896918 , -0.69673926, -0.16658142,  0.16339722, -0.35997954,\n",
       "          0.09035326,  0.4403643 ,  0.0274037 , -0.39044735,  0.5788313 ,\n",
       "          0.32709262, -0.50034964,  0.10176364,  0.9052467 ,  0.11608496,\n",
       "          0.0009929 , -0.21892658,  0.15353635,  0.56945556,  0.35338056,\n",
       "         -0.8448432 , -0.8089918 ,  0.38031456,  0.00607748,  0.7213647 ,\n",
       "         -0.19779271,  0.74084616, -0.07503837, -0.5096639 , -0.4006449 ,\n",
       "          0.42574587,  0.23661967],\n",
       "        [ 0.44914117,  0.09146658, -0.19291708,  0.36713228,  0.63660413,\n",
       "         -0.03387219, -0.5684994 ,  0.4184757 ,  0.286473  , -0.39309067,\n",
       "         -0.5176487 ,  0.12226472, -0.48108882,  0.0817736 ,  0.7591667 ,\n",
       "         -0.25242177,  0.27928752,  0.30189562, -0.28636947,  0.48229596,\n",
       "          0.8386778 , -0.5692107 ,  0.16694966,  0.04837588,  0.620662  ,\n",
       "         -0.85123384, -0.7009117 , -0.34315112,  0.4586416 , -0.3305178 ,\n",
       "         -0.31478956, -0.540943  ],\n",
       "        [ 0.01448971, -0.7126907 , -0.05646418, -0.43331775, -0.08311187,\n",
       "          0.31162366,  0.45765948, -0.18356268,  0.09287588,  0.8599306 ,\n",
       "         -0.29522023, -0.08897925,  0.95299745, -0.18773428, -0.6967796 ,\n",
       "          0.6873673 , -0.26118216, -0.33228645, -0.01750341,  0.30549756,\n",
       "         -0.10113747, -0.7585698 , -0.34682718, -0.5694586 ,  0.6722225 ,\n",
       "          0.51821584, -0.18115014,  0.32277438,  0.10754892, -0.55047244,\n",
       "         -0.4234972 , -0.63761   ],\n",
       "        [ 0.07421588,  0.0770927 , -0.09053484,  0.56380147, -0.28617632,\n",
       "          0.45279402,  0.5413489 , -0.4247524 ,  0.30872318,  0.5563932 ,\n",
       "         -0.2689322 ,  0.2553413 , -0.5083974 , -0.26692045,  0.25261626,\n",
       "          0.09349781, -0.06680705,  0.06294365, -0.5865869 , -0.6528411 ,\n",
       "          0.2520154 , -0.01746221,  0.04396841, -0.49539605,  0.05730405,\n",
       "          0.60130554, -0.15550315,  0.4202534 , -0.47196057, -0.33796695,\n",
       "         -0.160809  , -0.19223802],\n",
       "        [ 0.19221698, -0.7122129 ,  0.00916415,  0.30684134, -0.32079673,\n",
       "         -0.41352704,  0.37657133, -0.48046485, -0.20697235,  0.8490956 ,\n",
       "          0.3022174 , -0.0983367 , -0.16380833,  0.12009998,  0.92920095,\n",
       "         -0.00369289, -0.55204576, -0.1744129 ,  0.35861006, -0.07770531,\n",
       "          0.38809142,  0.18102019, -0.8304308 , -0.68958366, -0.14152655,\n",
       "          0.6927414 , -0.7835251 ,  0.06037666, -0.16078824,  0.09534108,\n",
       "          0.49547464,  0.5823632 ],\n",
       "        [ 0.08086803,  0.42779762,  0.68717414, -0.6745722 ,  0.6709803 ,\n",
       "         -0.7333385 ,  0.03460439, -0.50594515,  0.64263636,  0.7860251 ,\n",
       "         -0.13286129, -0.30765218,  0.737802  ,  0.18654798, -0.33267376,\n",
       "         -0.23694336, -0.07775466,  0.7228089 ,  0.2379302 , -0.3445198 ,\n",
       "          0.36407503, -0.0869728 , -0.6028922 , -0.29956096, -0.30196986,\n",
       "          0.6813487 , -0.06962171, -0.14921238,  0.28006944, -0.09399965,\n",
       "          0.38829938, -0.59269655]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[-0.44109184,  0.40233594,  0.31347814, ...,  0.43257132,\n",
       "         -0.40726706,  0.1362911 ],\n",
       "        [ 0.18030576,  0.01001937, -0.20437999, ...,  0.11977557,\n",
       "         -0.1844846 ,  0.4783257 ],\n",
       "        [-0.37955377, -0.23515566,  0.1351382 , ..., -0.02181546,\n",
       "         -0.11383068,  0.16084823],\n",
       "        ...,\n",
       "        [-0.3098634 , -0.00098271,  0.5589246 , ..., -0.07128085,\n",
       "         -0.0654657 ,  0.51874   ],\n",
       "        [ 0.125402  , -0.18787007, -0.3335165 , ..., -0.1451661 ,\n",
       "         -0.4071029 ,  0.25196102],\n",
       "        [ 0.309859  , -0.16921523,  0.21042474, ...,  0.14196299,\n",
       "          0.05435256,  0.23928647]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[ 0.17635465],\n",
       "        [-0.24752751],\n",
       "        [ 0.13089466],\n",
       "        [-0.29710108],\n",
       "        [ 0.21817338],\n",
       "        [ 0.19116485],\n",
       "        [ 0.24208277],\n",
       "        [ 0.00887713],\n",
       "        [ 0.0765214 ],\n",
       "        [-0.30428523],\n",
       "        [-0.29984826],\n",
       "        [-0.25350726],\n",
       "        [-0.35382664],\n",
       "        [-0.05715775],\n",
       "        [-0.1048466 ],\n",
       "        [ 0.40619928],\n",
       "        [-0.3660218 ],\n",
       "        [-0.24928911],\n",
       "        [-0.28737628],\n",
       "        [-0.18952872],\n",
       "        [ 0.2812991 ],\n",
       "        [ 0.09442949],\n",
       "        [ 0.01506633],\n",
       "        [-0.22204623],\n",
       "        [-0.30213323],\n",
       "        [ 0.07810855],\n",
       "        [-0.1069704 ],\n",
       "        [ 0.40871072],\n",
       "        [-0.0201979 ],\n",
       "        [-0.02646151],\n",
       "        [-0.06174108],\n",
       "        [-0.04274595]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "374/374 [==============================] - 1s 762us/step - loss: 2.8694 - accuracy: 0.5806 - val_loss: 1.5057 - val_accuracy: 0.7504\n",
      "Epoch 2/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 1.0674 - accuracy: 0.7223 - val_loss: 0.7202 - val_accuracy: 0.7906\n",
      "Epoch 3/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.6424 - accuracy: 0.7648 - val_loss: 0.5299 - val_accuracy: 0.7938\n",
      "Epoch 4/100\n",
      "374/374 [==============================] - 0s 552us/step - loss: 0.5305 - accuracy: 0.7811 - val_loss: 0.4737 - val_accuracy: 0.8059\n",
      "Epoch 5/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.5047 - accuracy: 0.7945 - val_loss: 0.4532 - val_accuracy: 0.8139\n",
      "Epoch 6/100\n",
      "374/374 [==============================] - 0s 557us/step - loss: 0.4885 - accuracy: 0.7981 - val_loss: 0.4351 - val_accuracy: 0.8252\n",
      "Epoch 7/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 0.4806 - accuracy: 0.8010 - val_loss: 0.4352 - val_accuracy: 0.8232\n",
      "Epoch 8/100\n",
      "374/374 [==============================] - 0s 547us/step - loss: 0.4784 - accuracy: 0.7976 - val_loss: 0.4354 - val_accuracy: 0.8250\n",
      "Epoch 9/100\n",
      "374/374 [==============================] - 0s 624us/step - loss: 0.4810 - accuracy: 0.8032 - val_loss: 0.4310 - val_accuracy: 0.8194\n",
      "Epoch 10/100\n",
      "374/374 [==============================] - 0s 548us/step - loss: 0.4741 - accuracy: 0.8048 - val_loss: 0.4201 - val_accuracy: 0.8252\n",
      "Epoch 11/100\n",
      "374/374 [==============================] - 0s 547us/step - loss: 0.4683 - accuracy: 0.7997 - val_loss: 0.4217 - val_accuracy: 0.8219\n",
      "Epoch 12/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4681 - accuracy: 0.8040 - val_loss: 0.4241 - val_accuracy: 0.8240\n",
      "Epoch 13/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4735 - accuracy: 0.8053 - val_loss: 0.4260 - val_accuracy: 0.8250\n",
      "Epoch 14/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4725 - accuracy: 0.8044 - val_loss: 0.4168 - val_accuracy: 0.8255\n",
      "Epoch 15/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4711 - accuracy: 0.8019 - val_loss: 0.4251 - val_accuracy: 0.8207\n",
      "Epoch 16/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4712 - accuracy: 0.8038 - val_loss: 0.4195 - val_accuracy: 0.8245\n",
      "Epoch 17/100\n",
      "374/374 [==============================] - 0s 557us/step - loss: 0.4700 - accuracy: 0.8013 - val_loss: 0.4149 - val_accuracy: 0.8270\n",
      "Epoch 18/100\n",
      "374/374 [==============================] - 0s 556us/step - loss: 0.4676 - accuracy: 0.8030 - val_loss: 0.4177 - val_accuracy: 0.8219\n",
      "Epoch 19/100\n",
      "374/374 [==============================] - 0s 623us/step - loss: 0.4696 - accuracy: 0.7998 - val_loss: 0.4259 - val_accuracy: 0.8184\n",
      "Epoch 20/100\n",
      "374/374 [==============================] - 0s 567us/step - loss: 0.4691 - accuracy: 0.8016 - val_loss: 0.4200 - val_accuracy: 0.8240\n",
      "Epoch 21/100\n",
      "374/374 [==============================] - 0s 558us/step - loss: 0.4674 - accuracy: 0.8058 - val_loss: 0.4189 - val_accuracy: 0.8197\n",
      "Epoch 22/100\n",
      "374/374 [==============================] - 0s 560us/step - loss: 0.4692 - accuracy: 0.8028 - val_loss: 0.4182 - val_accuracy: 0.8260\n",
      "Epoch 23/100\n",
      "374/374 [==============================] - 0s 557us/step - loss: 0.4748 - accuracy: 0.8012 - val_loss: 0.4231 - val_accuracy: 0.8260\n",
      "Epoch 24/100\n",
      "374/374 [==============================] - 0s 557us/step - loss: 0.4669 - accuracy: 0.8055 - val_loss: 0.4193 - val_accuracy: 0.8265\n",
      "Epoch 25/100\n",
      "374/374 [==============================] - 0s 558us/step - loss: 0.4742 - accuracy: 0.8018 - val_loss: 0.4166 - val_accuracy: 0.8277\n",
      "Epoch 26/100\n",
      "374/374 [==============================] - 0s 557us/step - loss: 0.4642 - accuracy: 0.8058 - val_loss: 0.4169 - val_accuracy: 0.8257\n",
      "Epoch 27/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4680 - accuracy: 0.8090 - val_loss: 0.4165 - val_accuracy: 0.8272\n",
      "Epoch 28/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4749 - accuracy: 0.7971 - val_loss: 0.4206 - val_accuracy: 0.8250\n",
      "Epoch 29/100\n",
      "374/374 [==============================] - 0s 548us/step - loss: 0.4670 - accuracy: 0.8054 - val_loss: 0.4121 - val_accuracy: 0.8297\n",
      "Epoch 30/100\n",
      "374/374 [==============================] - 0s 621us/step - loss: 0.4763 - accuracy: 0.8038 - val_loss: 0.4149 - val_accuracy: 0.8287\n",
      "Epoch 31/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4687 - accuracy: 0.8038 - val_loss: 0.4273 - val_accuracy: 0.8247\n",
      "Epoch 32/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4692 - accuracy: 0.8043 - val_loss: 0.4200 - val_accuracy: 0.8192\n",
      "Epoch 33/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4690 - accuracy: 0.8066 - val_loss: 0.4200 - val_accuracy: 0.8265\n",
      "Epoch 34/100\n",
      "374/374 [==============================] - 0s 548us/step - loss: 0.4656 - accuracy: 0.8068 - val_loss: 0.4161 - val_accuracy: 0.8250\n",
      "Epoch 35/100\n",
      "374/374 [==============================] - 0s 555us/step - loss: 0.4721 - accuracy: 0.7988 - val_loss: 0.4204 - val_accuracy: 0.8250\n",
      "Epoch 36/100\n",
      "374/374 [==============================] - 0s 558us/step - loss: 0.4699 - accuracy: 0.8002 - val_loss: 0.4211 - val_accuracy: 0.8230\n",
      "Epoch 37/100\n",
      "374/374 [==============================] - 0s 559us/step - loss: 0.4727 - accuracy: 0.8029 - val_loss: 0.4248 - val_accuracy: 0.8315\n",
      "Epoch 38/100\n",
      "374/374 [==============================] - 0s 560us/step - loss: 0.4715 - accuracy: 0.8026 - val_loss: 0.4176 - val_accuracy: 0.8247\n",
      "Epoch 39/100\n",
      "374/374 [==============================] - 0s 557us/step - loss: 0.4667 - accuracy: 0.8074 - val_loss: 0.4195 - val_accuracy: 0.8230\n",
      "Epoch 40/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4699 - accuracy: 0.7999 - val_loss: 0.4180 - val_accuracy: 0.8265\n",
      "Epoch 41/100\n",
      "374/374 [==============================] - 0s 630us/step - loss: 0.4702 - accuracy: 0.8068 - val_loss: 0.4219 - val_accuracy: 0.8214\n",
      "Epoch 42/100\n",
      "374/374 [==============================] - 0s 579us/step - loss: 0.4701 - accuracy: 0.8061 - val_loss: 0.4189 - val_accuracy: 0.8245\n",
      "Epoch 43/100\n",
      "374/374 [==============================] - 0s 556us/step - loss: 0.4664 - accuracy: 0.8036 - val_loss: 0.4190 - val_accuracy: 0.8257\n",
      "Epoch 44/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4644 - accuracy: 0.8053 - val_loss: 0.4174 - val_accuracy: 0.8194\n",
      "Epoch 45/100\n",
      "374/374 [==============================] - 0s 556us/step - loss: 0.4670 - accuracy: 0.8042 - val_loss: 0.4203 - val_accuracy: 0.8260\n",
      "Epoch 46/100\n",
      "374/374 [==============================] - 0s 555us/step - loss: 0.4643 - accuracy: 0.8029 - val_loss: 0.4269 - val_accuracy: 0.8280\n",
      "Epoch 47/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 0.4673 - accuracy: 0.8027 - val_loss: 0.4152 - val_accuracy: 0.8260\n",
      "Epoch 48/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4702 - accuracy: 0.8070 - val_loss: 0.4216 - val_accuracy: 0.8272\n",
      "Epoch 49/100\n",
      "374/374 [==============================] - 0s 547us/step - loss: 0.4726 - accuracy: 0.8053 - val_loss: 0.4220 - val_accuracy: 0.8199\n",
      "Epoch 50/100\n",
      "374/374 [==============================] - 0s 552us/step - loss: 0.4715 - accuracy: 0.8027 - val_loss: 0.4196 - val_accuracy: 0.8250\n",
      "Epoch 51/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4680 - accuracy: 0.8056 - val_loss: 0.4157 - val_accuracy: 0.8327\n",
      "Epoch 52/100\n",
      "374/374 [==============================] - 0s 622us/step - loss: 0.4684 - accuracy: 0.8027 - val_loss: 0.4201 - val_accuracy: 0.8245\n",
      "Epoch 53/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4646 - accuracy: 0.8056 - val_loss: 0.4199 - val_accuracy: 0.8262\n",
      "Epoch 54/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 0.4628 - accuracy: 0.8079 - val_loss: 0.4174 - val_accuracy: 0.8265\n",
      "Epoch 55/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4641 - accuracy: 0.8032 - val_loss: 0.4305 - val_accuracy: 0.8172\n",
      "Epoch 56/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4693 - accuracy: 0.8086 - val_loss: 0.4223 - val_accuracy: 0.8295\n",
      "Epoch 57/100\n",
      "374/374 [==============================] - 0s 565us/step - loss: 0.4720 - accuracy: 0.7984 - val_loss: 0.4202 - val_accuracy: 0.8255\n",
      "Epoch 58/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4708 - accuracy: 0.8029 - val_loss: 0.4170 - val_accuracy: 0.8245\n",
      "Epoch 59/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4684 - accuracy: 0.8026 - val_loss: 0.4204 - val_accuracy: 0.8247\n",
      "Epoch 60/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4683 - accuracy: 0.8091 - val_loss: 0.4253 - val_accuracy: 0.8247\n",
      "Epoch 61/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4750 - accuracy: 0.8012 - val_loss: 0.4206 - val_accuracy: 0.8242\n",
      "Epoch 62/100\n",
      "374/374 [==============================] - 0s 548us/step - loss: 0.4652 - accuracy: 0.8043 - val_loss: 0.4222 - val_accuracy: 0.8192\n",
      "Epoch 63/100\n",
      "374/374 [==============================] - 0s 626us/step - loss: 0.4664 - accuracy: 0.8124 - val_loss: 0.4207 - val_accuracy: 0.8270\n",
      "Epoch 64/100\n",
      "374/374 [==============================] - 0s 558us/step - loss: 0.4679 - accuracy: 0.8068 - val_loss: 0.4143 - val_accuracy: 0.8257\n",
      "Epoch 65/100\n",
      "374/374 [==============================] - 0s 556us/step - loss: 0.4638 - accuracy: 0.8083 - val_loss: 0.4187 - val_accuracy: 0.8235\n",
      "Epoch 66/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4661 - accuracy: 0.8076 - val_loss: 0.4190 - val_accuracy: 0.8204\n",
      "Epoch 67/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4634 - accuracy: 0.8063 - val_loss: 0.4226 - val_accuracy: 0.8217\n",
      "Epoch 68/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4682 - accuracy: 0.8053 - val_loss: 0.4166 - val_accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4689 - accuracy: 0.8041 - val_loss: 0.4172 - val_accuracy: 0.8280\n",
      "Epoch 70/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4645 - accuracy: 0.8032 - val_loss: 0.4139 - val_accuracy: 0.8265\n",
      "Epoch 71/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 0.4634 - accuracy: 0.8104 - val_loss: 0.4195 - val_accuracy: 0.8245\n",
      "Epoch 72/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4709 - accuracy: 0.8020 - val_loss: 0.4174 - val_accuracy: 0.8247\n",
      "Epoch 73/100\n",
      "374/374 [==============================] - 0s 565us/step - loss: 0.4675 - accuracy: 0.8076 - val_loss: 0.4167 - val_accuracy: 0.8225\n",
      "Epoch 74/100\n",
      "374/374 [==============================] - 0s 624us/step - loss: 0.4653 - accuracy: 0.8123 - val_loss: 0.4164 - val_accuracy: 0.8235\n",
      "Epoch 75/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4692 - accuracy: 0.8084 - val_loss: 0.4302 - val_accuracy: 0.8247\n",
      "Epoch 76/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4630 - accuracy: 0.8099 - val_loss: 0.4147 - val_accuracy: 0.8277\n",
      "Epoch 77/100\n",
      "374/374 [==============================] - 0s 555us/step - loss: 0.4724 - accuracy: 0.8050 - val_loss: 0.4227 - val_accuracy: 0.8184\n",
      "Epoch 78/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4708 - accuracy: 0.8037 - val_loss: 0.4166 - val_accuracy: 0.8252\n",
      "Epoch 79/100\n",
      "374/374 [==============================] - 0s 553us/step - loss: 0.4737 - accuracy: 0.8044 - val_loss: 0.4174 - val_accuracy: 0.8300\n",
      "Epoch 80/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4686 - accuracy: 0.8055 - val_loss: 0.4195 - val_accuracy: 0.8282\n",
      "Epoch 81/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4714 - accuracy: 0.8045 - val_loss: 0.4185 - val_accuracy: 0.8272\n",
      "Epoch 82/100\n",
      "374/374 [==============================] - 0s 547us/step - loss: 0.4658 - accuracy: 0.8115 - val_loss: 0.4179 - val_accuracy: 0.8250\n",
      "Epoch 83/100\n",
      "374/374 [==============================] - 0s 608us/step - loss: 0.4688 - accuracy: 0.8084 - val_loss: 0.4158 - val_accuracy: 0.8252\n",
      "Epoch 84/100\n",
      "374/374 [==============================] - 0s 555us/step - loss: 0.4683 - accuracy: 0.8058 - val_loss: 0.4137 - val_accuracy: 0.8307\n",
      "Epoch 85/100\n",
      "374/374 [==============================] - 0s 556us/step - loss: 0.4639 - accuracy: 0.8069 - val_loss: 0.4266 - val_accuracy: 0.8192\n",
      "Epoch 86/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4710 - accuracy: 0.8043 - val_loss: 0.4157 - val_accuracy: 0.8242\n",
      "Epoch 87/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 0.4755 - accuracy: 0.8041 - val_loss: 0.4207 - val_accuracy: 0.8237\n",
      "Epoch 88/100\n",
      "374/374 [==============================] - 0s 552us/step - loss: 0.4720 - accuracy: 0.8034 - val_loss: 0.4153 - val_accuracy: 0.8242\n",
      "Epoch 89/100\n",
      "374/374 [==============================] - 0s 548us/step - loss: 0.4720 - accuracy: 0.8027 - val_loss: 0.4182 - val_accuracy: 0.8262\n",
      "Epoch 90/100\n",
      "374/374 [==============================] - 0s 548us/step - loss: 0.4703 - accuracy: 0.8063 - val_loss: 0.4167 - val_accuracy: 0.8237\n",
      "Epoch 91/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4684 - accuracy: 0.8023 - val_loss: 0.4142 - val_accuracy: 0.8272\n",
      "Epoch 92/100\n",
      "374/374 [==============================] - 0s 554us/step - loss: 0.4683 - accuracy: 0.8023 - val_loss: 0.4210 - val_accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "374/374 [==============================] - 0s 625us/step - loss: 0.4667 - accuracy: 0.8095 - val_loss: 0.4197 - val_accuracy: 0.8275\n",
      "Epoch 94/100\n",
      "374/374 [==============================] - 0s 551us/step - loss: 0.4733 - accuracy: 0.8037 - val_loss: 0.4187 - val_accuracy: 0.8240\n",
      "Epoch 95/100\n",
      "374/374 [==============================] - 0s 565us/step - loss: 0.4659 - accuracy: 0.8049 - val_loss: 0.4191 - val_accuracy: 0.8285\n",
      "Epoch 96/100\n",
      "374/374 [==============================] - 0s 546us/step - loss: 0.4727 - accuracy: 0.8038 - val_loss: 0.4221 - val_accuracy: 0.8212\n",
      "Epoch 97/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4675 - accuracy: 0.8073 - val_loss: 0.4143 - val_accuracy: 0.8240\n",
      "Epoch 98/100\n",
      "374/374 [==============================] - 0s 549us/step - loss: 0.4701 - accuracy: 0.8002 - val_loss: 0.4166 - val_accuracy: 0.8235\n",
      "Epoch 99/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4718 - accuracy: 0.8024 - val_loss: 0.4182 - val_accuracy: 0.8255\n",
      "Epoch 100/100\n",
      "374/374 [==============================] - 0s 550us/step - loss: 0.4647 - accuracy: 0.8053 - val_loss: 0.4235 - val_accuracy: 0.8217\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dropout and batch normalization, etc to check model score improvements\n",
    "# Multi layer preceptron\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu',kernel_regularizer=keras.regularizers.L2(0.03), input_dim=11, kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=keras.regularizers.L2(0.03), kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
